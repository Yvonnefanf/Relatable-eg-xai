{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load data\n",
    "# Load data\n",
    "\n",
    "pd_data = pd.read_csv('../../datasets/auto-mpg.csv')\n",
    "\n",
    "# Handle missing values marked as '?'\n",
    "pd_data = pd_data.replace(\"?\", np.nan)  \n",
    "pd_data = pd_data.dropna()  \n",
    "\n",
    "# Convert categorical variables to numeric using label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "categorical_columns = pd_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    pd_data[col] = le.fit_transform(pd_data[col])\n",
    "\n",
    "# Convert horsepower to float\n",
    "pd_data = pd_data.astype({\"horsepower\": float})\n",
    "\n",
    "# Prepare features and target\n",
    "X = pd_data.drop(columns=['mpg'])\n",
    "y = pd_data['mpg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886177057582073\n",
      "2.410308977514835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test) \n",
    "r2_socre_ = r2_score(y_test, preds)\n",
    "print(r2_socre_)\n",
    "rmse_score = np.sqrt(np.mean((y_test - preds) ** 2))\n",
    "print(rmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto 23.451 label 23.8\n",
      "X_proto [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02] pred_prototype adj 23.507\n",
      "X_target [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02] pred_target 23.507\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02], f(x) = 23.507\n",
      "error: 1 0.0 error means 0.0\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto 43.719000000000044 label 44.3\n",
      "X_proto [   4.    91.    49.  2085.    21.7   80.     3.   299. ] pred_prototype adj 43.02300000000004\n",
      "X_target [   4.    91.    55.  1800.    16.4   78.     3.   169. ] pred_target 34.927999999999976\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "train_preds = rf.predict(X_train)\n",
    "\n",
    "min_index = np.argmin(train_preds)  # min val index\n",
    "max_index = np.argmax(train_preds)  # max val index\n",
    "mean_value = np.mean(train_preds)   # mean val \n",
    "\n",
    "closest_mean_index = np.argmin(np.abs(train_preds - mean_value))  # 找到最接近均值的索引\n",
    "\n",
    "\n",
    "# Define function f(x) using rf.predict.\n",
    "def f(x):\n",
    "    x_df = pd.DataFrame([x], columns=X.columns)\n",
    "    return float(rf.predict(x_df)[0])\n",
    "\n",
    "\n",
    "#run experiments\n",
    "from Approach import run_search_path\n",
    "prototypes = X_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "prototype_labels = y_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "Errors = []\n",
    "each_step_avg_errs = []\n",
    "No_path_index = []\n",
    "for i in range(1,len(X_test)):\n",
    "    try:\n",
    "        error, avg_step_error = run_search_path(f, prototypes, prototype_labels, X_test.iloc[i].values)\n",
    "        print(\"error:\", i, error, 'error means', np.array(avg_step_error).mean() / preds.mean())       \n",
    "        if error is not None:\n",
    "            Errors.append(error)\n",
    "            each_step_avg_errs.append(avg_step_error)\n",
    "        else:\n",
    "            No_path_index.append(i)\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {i}: {e}, skipping this iteration.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06445111106310662"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(each_step_avg_errs).mean() / preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746835443037974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Errors) /len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cylinders          8.0\n",
       "displacement     304.0\n",
       "horsepower        39.0\n",
       "weight          4732.0\n",
       "acceleration      18.5\n",
       "model year        70.0\n",
       "origin             1.0\n",
       "car name         161.0\n",
       "Name: 28, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Define our function f(x) using rf.predict.\n",
    "# def f(x):\n",
    "#     x_df = pd.DataFrame([x], columns=X.columns)\n",
    "#     return float(rf.predict(x_df)[0])\n",
    "\n",
    "def f(x):\n",
    "    # 支持单个样本和批量样本\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    x_df = pd.DataFrame(x, columns=X.columns)\n",
    "    return rf.predict(x_df).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def dynamic_feature_filter(x_proto, x_target, num_samples=10, threshold=0.1):\n",
    "    \"\"\"\n",
    "    classify features as low- or high-sensitivity by computing\n",
    "    the variance of predictions when varying each feature, and then clustering \n",
    "    the variances using k-means.\n",
    "    \n",
    "    Parameters:\n",
    "      x_proto: 1D numpy array for the prototype.\n",
    "      x_target: 1D numpy array for the target.\n",
    "      num_samples: Number of interpolation points per feature.\n",
    "    \n",
    "    Returns:\n",
    "      variances: Array of variance values for each feature.\n",
    "      low_variance_features: List of indices of features with low sensitivity.\n",
    "      high_variance_features: List of indices of features with high sensitivity.\n",
    "    \"\"\"\n",
    "    x_proto_adj = np.copy(x_proto)\n",
    "    n_features = len(x_proto)\n",
    "    variances = np.zeros(n_features)\n",
    "    low_variance_features = []\n",
    "    high_variance_features = []\n",
    "    for i in range(n_features):\n",
    "        # Generate interpolation values for the i-th feature.\n",
    "        interp_vals = np.linspace(x_proto[i], x_target[i], num_samples)\n",
    "        preds = []\n",
    "        for val in interp_vals:\n",
    "            x_temp = np.copy(x_proto)\n",
    "            x_temp[i] = val  # Vary only the i-th feature.\n",
    "            preds.append(f(x_temp))\n",
    "        preds = np.array(preds)\n",
    "        var_val = np.var(preds)\n",
    "        variances[i] = var_val\n",
    "        if var_val < threshold:\n",
    "          x_proto_adj[i] = x_target[i]\n",
    "          low_variance_features.append(i)\n",
    "        else:\n",
    "          high_variance_features.append(i)\n",
    "    return x_proto_adj, variances, low_variance_features, high_variance_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid generation that fixes low-variance features.\n",
    "def generate_grid_with_filter(x_proto_adj, x_target, partitions, low_variance_features):\n",
    "    \"\"\"\n",
    "    For low-variance features, use a grid with a single point (the target).\n",
    "    For high-variance features, generate a grid between x_proto_adj and x_target.\n",
    "    \"\"\"\n",
    "    grid = []\n",
    "    n_features = len(x_proto_adj)\n",
    "    for i in range(n_features):\n",
    "        if i in low_variance_features:\n",
    "            grid.append(np.array([x_target[i]]))\n",
    "        else:\n",
    "            grid.append(np.linspace(x_proto_adj[i], x_target[i], partitions + 1))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def local_linear_error(x_start, x_end, f_start, f_end, num_samples=10):\n",
    "    \"\"\"\n",
    "    Compute the average squared error between the true function f(x)\n",
    "    and its linear interpolation between (x_start, f_start) and (x_end, f_end)\n",
    "    \"\"\"\n",
    "    t_vals = np.linspace(0, 1, num_samples)\n",
    "    error_sum = 0.0\n",
    "    for t in t_vals:\n",
    "        x_interp = x_start + t * (x_end - x_start)\n",
    "        f_interp = f_start + t * (f_end - f_start)\n",
    "        f_actual = f(x_interp)\n",
    "        error_sum += abs(f_actual - f_interp)\n",
    "    return error_sum\n",
    "# def local_linear_error(x_start, x_end, f_start, f_end, num_samples=10):\n",
    "#     \"\"\"批量计算线性插值误差\"\"\"\n",
    "#     t_vals = np.linspace(0, 1, num_samples)\n",
    "#     # 批量生成插值点\n",
    "#     x_interp = x_start + np.outer(t_vals, (x_end - x_start))\n",
    "#     f_interp = f_start + t_vals * (f_end - f_start)\n",
    "#     f_actual = f(x_interp)\n",
    "#     return np.mean((f_actual - f_interp) ** 2)\n",
    "\n",
    "def heuristic(current_x, target_x, current_f, target_f, num_samples=10):\n",
    "    \"\"\"\n",
    "    A simple heuristic: the local linear error from the current point to the target.\n",
    "    This is admissible if f is reasonably smooth.\n",
    "    \"\"\"\n",
    "    return local_linear_error(current_x, target_x, current_f, target_f, num_samples)\n",
    "def a_star_search(initial_state, initial_x, f_proto, target_x, f_target, grid, max_steps, monotonic_increasing, tol=1e-6):\n",
    "    \"\"\"\n",
    "    A* search in the discretized feature space.\n",
    "    \"\"\"\n",
    "    # Get the actual number of partitions for each dimension\n",
    "    partitions = [len(grid[i]) - 1 for i in range(len(grid))]\n",
    "    d = len(initial_state)\n",
    "    counter = 0\n",
    "    \n",
    "    # Each item in the heap is a tuple: (estimated_total_cost, cumulative_error, state, path, f_values, steps)\n",
    "    start_item = (heuristic(initial_x, target_x, f_proto, f_target), 0.0,counter, initial_state, [initial_x], [f_proto], 0)\n",
    "    heap = [start_item]\n",
    "    best_solution = None\n",
    "    visited = {}  # records the best cumulative error reached for a given state\n",
    "\n",
    "    while heap:\n",
    "        est_cost, cum_error, counter, state, path, f_values, steps = heapq.heappop(heap)\n",
    "        \n",
    "        # Skip if we've seen this state with a lower cost already\n",
    "        if state in visited and visited[state] <= cum_error:\n",
    "            continue\n",
    "        visited[state] = cum_error\n",
    "        \n",
    "        # Check if we've reached the target state\n",
    "        # print(\"state\")\n",
    "        if all(state[i] == partitions[i] for i in range(d)):\n",
    "            best_solution = {'path': path, 'f_values': f_values, 'error': cum_error}\n",
    "            break\n",
    "        \n",
    "        # If maximum steps have been reached, update the best solution if it's better\n",
    "        if steps >= max_steps:\n",
    "            if best_solution is None or cum_error < best_solution['error']:\n",
    "                best_solution = {'path': path, 'f_values': f_values, 'error': cum_error}\n",
    "            continue\n",
    "\n",
    "        current_x = np.array([grid[i][state[i]] for i in range(d)])\n",
    "        current_f = f_values[-1]\n",
    "        \n",
    "        # Expand the current state: try to update one feature at a time\n",
    "        for i in range(d):\n",
    "            if state[i] < partitions[i]:  # Check against dimension-specific partition size\n",
    "                # Allow stepping 1 to the remaining number of grid points in dimension i\n",
    "                for step_size in range(1, partitions[i] - state[i] + 1):\n",
    "                    new_state = list(state)\n",
    "                    new_state[i] += step_size\n",
    "                    new_state = tuple(new_state)\n",
    "                    \n",
    "                    new_x = np.array([grid[j][new_state[j]] for j in range(d)])\n",
    "                    # new_f = f(new_x)\n",
    "                    \n",
    "                    # # Check monotonicity constraints (with tolerance)\n",
    "                    # if monotonic_increasing and new_f < current_f - tol:\n",
    "                    #     continue\n",
    "                    # if not monotonic_increasing and new_f > current_f + tol:\n",
    "                    #     continue\n",
    "                    # Check monotonicity constraints (with tolerance)\n",
    "                    new_f = float(f(new_x)[0])  # Convert to scalar\n",
    "                    current_f = float(current_f)  # Ensure current_f is also scalar\n",
    "                    \n",
    "                    # Check monotonicity constraints (with tolerance)\n",
    "                    if monotonic_increasing and new_f < current_f - tol:\n",
    "                        continue\n",
    "                    if not monotonic_increasing and new_f > current_f + tol:\n",
    "                        continue\n",
    "                  \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    local_err = local_linear_error(current_x, new_x, current_f, new_f)\n",
    "                    new_cum_error = cum_error + local_err\n",
    "                    \n",
    "                    # Compute heuristic from new state to target\n",
    "                    h = heuristic(new_x, target_x, new_f, f_target)\n",
    "                  \n",
    "                    # new_est_cost = new_cum_error + h\n",
    "                    new_est_cost = float(new_cum_error + h)\n",
    "                    new_path = path + [new_x]\n",
    "                    new_f_values = f_values + [new_f]\n",
    "                    # print(\"1\",new_est_cost, new_cum_error, new_state, new_path, new_f_values)\n",
    "                    counter += 1\n",
    "                    # heapq.heappush(heap, (new_est_cost, new_cum_error, counter, new_state, new_path, new_f_values, steps + 1))\n",
    "                    heapq.heappush(heap, (new_est_cost, new_cum_error, counter, new_state, new_path, new_f_values, steps + 1))\n",
    "                    \n",
    "    return best_solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search_path(prototypes, X_target,partitions=2,max_steps=5):\n",
    "    # Choose a test instance to explain (e.g., the first one)\n",
    "    f_target = f(X_target)\n",
    "    # Define multiple prototype candidates\n",
    "    # Compute distances to X_target\n",
    "    distances = np.linalg.norm(prototypes - X_target, axis=1)\n",
    "    # Select the closest prototype\n",
    "    closest_proto_index = np.argmin(distances)\n",
    "    X_proto = prototypes[closest_proto_index]\n",
    "    #### identify noise directions\n",
    "    x_proto_adj, variances, low_variance_features, high_variance_features = dynamic_feature_filter(X_proto, X_target)\n",
    "    grid = generate_grid_with_filter(x_proto_adj, X_target, partitions, low_variance_features)\n",
    "    \n",
    "    \n",
    "    d = len(X_proto)\n",
    "    initial_state = tuple([0] * d)\n",
    "    initial_x = np.array([grid[i][0] for i in range(d)])  # 与 x_proto 应相同\n",
    "    f_proto = f(initial_x)\n",
    "    f_target = f(X_target)\n",
    "    # identify the monotonic direction\n",
    "    monotonic_increasing = (f_target >= f_proto)\n",
    "\n",
    "    print(\"X_proto\",X_proto, 'org_proto', f(X_proto))\n",
    "    print(\"X_proto\",x_proto_adj, 'pred_prototype adj', f(x_proto_adj))\n",
    "    print(\"X_target\",X_target,'pred_target', f_target)\n",
    "    # result = dfs(initial_state, [initial_x], [f_proto], 0.0, grid, max_steps, monotonic_increasing, tol=1e-6)\n",
    "    result = a_star_search(initial_state, initial_x, f_proto, X_target, f_target, grid, max_steps, monotonic_increasing)\n",
    "    #\n",
    "\n",
    "\n",
    "    if result is not None:\n",
    "        print(\"Found a path:\")\n",
    "        for i, (x_val, fx_val) in enumerate(zip(result['path'], result['f_values'])):\n",
    "            print(f\"Step {i}: x = {x_val}, f(x) = {fx_val}\")\n",
    "        print(\"Cumulative error:\", result['error'])\n",
    "        return result['error']\n",
    "    else:\n",
    "        print(\"No path found.\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] pred_prototype adj [43.719]\n",
      "X_target [4.000e+00 9.600e+01 6.400e+01 2.189e+03 1.800e+01 7.200e+01 2.000e+00\n",
      " 2.510e+02] pred_target [26.02]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = [43.719]\n",
      "Step 1: x = [4.000e+00 9.000e+01 4.900e+01 2.137e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.63500000000003\n",
      "Step 2: x = [4.000e+00 9.000e+01 4.900e+01 2.137e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.750e+02], f(x) = 42.068000000000005\n",
      "Step 3: x = [4.000e+00 9.000e+01 4.900e+01 2.137e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.510e+02], f(x) = 42.00200000000001\n",
      "Step 4: x = [4.000e+00 9.000e+01 4.900e+01 2.189e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.510e+02], f(x) = 41.166000000000004\n",
      "Step 5: x = [4.000e+00 9.000e+01 5.650e+01 2.189e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.510e+02], f(x) = 40.357000000000006\n",
      "Cumulative error: [6.29833333]\n",
      "error: 0 [6.29833333]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02] pred_prototype adj [23.507]\n",
      "X_target [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02] pred_target [23.507]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.210e+02 9.000e+00 2.795e+03 1.570e+01 7.800e+01 2.000e+00\n",
      " 2.550e+02], f(x) = [23.507]\n",
      "Cumulative error: 0.0\n",
      "error: 1 0.0\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    91.    49.  2085.    21.7   80.     3.   299. ] pred_prototype adj [43.023]\n",
      "X_target [   4.    91.    55.  1800.    16.4   78.     3.   169. ] pred_target [34.928]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    91.    49.  2085.    21.7   80.     3.   299. ], f(x) = [43.023]\n",
      "Step 1: x = [   4.    91.    49.  1800.    21.7   80.     3.   299. ], f(x) = 41.834000000000024\n",
      "Step 2: x = [   4.    91.    49.  1800.    21.7   78.     3.   299. ], f(x) = 39.286\n",
      "Step 3: x = [   4.    91.    49.  1800.    16.4   78.     3.   299. ], f(x) = 35.663999999999994\n",
      "Step 4: x = [   4.    91.    49.  1800.    16.4   78.     3.   169. ], f(x) = 35.32399999999998\n",
      "Step 5: x = [   4.    91.    55.  1800.    16.4   78.     3.   169. ], f(x) = 34.927999999999976\n",
      "Cumulative error: [13.90855556]\n",
      "error: 2 [13.90855556]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.000e+00 9.100e+01 4.900e+01 2.085e+03 2.050e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02] pred_prototype adj [42.907]\n",
      "X_target [4.000e+00 9.100e+01 6.500e+01 1.955e+03 2.050e+01 7.100e+01 1.000e+00\n",
      " 2.160e+02] pred_target [30.041]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 9.100e+01 4.900e+01 2.085e+03 2.050e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = [42.907]\n",
      "Step 1: x = [4.000e+00 9.100e+01 6.500e+01 2.085e+03 2.050e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = 40.43600000000003\n",
      "Step 2: x = [4.000e+00 9.100e+01 6.500e+01 1.955e+03 2.050e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = 38.859\n",
      "Step 3: x = [4.000e+00 9.100e+01 6.500e+01 1.955e+03 2.050e+01 8.000e+01 1.000e+00\n",
      " 2.160e+02], f(x) = 37.33499999999998\n",
      "Step 4: x = [4.000e+00 9.100e+01 6.500e+01 1.955e+03 2.050e+01 7.100e+01 1.000e+00\n",
      " 2.160e+02], f(x) = 30.041\n",
      "Cumulative error: [22.02711111]\n",
      "error: 3 [22.02711111]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.00e+00 1.40e+02 8.00e+01 2.79e+03 1.56e+01 7.80e+01 1.00e+00 1.51e+02] pred_prototype adj [24.32]\n",
      "X_target [4.00e+00 1.40e+02 8.00e+01 2.79e+03 1.56e+01 8.20e+01 1.00e+00 1.51e+02] pred_target [26.584]\n",
      "Found a path:\n",
      "Step 0: x = [4.00e+00 1.40e+02 8.00e+01 2.79e+03 1.56e+01 7.80e+01 1.00e+00 1.51e+02], f(x) = [24.32]\n",
      "Step 1: x = [4.00e+00 1.40e+02 8.00e+01 2.79e+03 1.56e+01 8.00e+01 1.00e+00 1.51e+02], f(x) = 26.530000000000015\n",
      "Step 2: x = [4.00e+00 1.40e+02 8.00e+01 2.79e+03 1.56e+01 8.20e+01 1.00e+00 1.51e+02], f(x) = 26.584000000000007\n",
      "Cumulative error: [2.802]\n",
      "error: 4 [2.802]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    90.    49.  2155.    21.7   80.     3.   299. ] pred_prototype adj [42.87]\n",
      "X_target [   4.    97.    69.  2155.    16.4   76.     3.   262. ] pred_target [28.022]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    90.    49.  2155.    21.7   80.     3.   299. ], f(x) = [42.87]\n",
      "Step 1: x = [   4.    90.    69.  2155.    21.7   80.     3.   299. ], f(x) = 40.857000000000035\n",
      "Step 2: x = [   4.    97.    69.  2155.    21.7   80.     3.   299. ], f(x) = 39.314000000000036\n",
      "Step 3: x = [   4.    97.    69.  2155.    16.4   80.     3.   299. ], f(x) = 36.29000000000002\n",
      "Step 4: x = [   4.    97.    69.  2155.    16.4   76.     3.   299. ], f(x) = 28.087\n",
      "Step 5: x = [   4.    97.    69.  2155.    16.4   76.     3.   262. ], f(x) = 28.022\n",
      "Cumulative error: [12.73144444]\n",
      "error: 5 [12.73144444]\n",
      "X_proto [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02] org_proto [10.456]\n",
      "X_proto [8.000e+00 4.000e+02 3.500e+01 4.746e+03 1.850e+01 7.100e+01 1.000e+00\n",
      " 1.280e+02] pred_prototype adj [11.802]\n",
      "X_target [8.000e+00 4.000e+02 3.500e+01 4.746e+03 1.200e+01 7.100e+01 1.000e+00\n",
      " 1.280e+02] pred_target [12.33]\n",
      "Found a path:\n",
      "Step 0: x = [8.000e+00 4.000e+02 3.500e+01 4.746e+03 1.850e+01 7.100e+01 1.000e+00\n",
      " 1.280e+02], f(x) = [11.802]\n",
      "Step 1: x = [8.000e+00 4.000e+02 3.500e+01 4.746e+03 1.525e+01 7.100e+01 1.000e+00\n",
      " 1.280e+02], f(x) = 11.936\n",
      "Step 2: x = [8.000e+00 4.000e+02 3.500e+01 4.746e+03 1.200e+01 7.100e+01 1.000e+00\n",
      " 1.280e+02], f(x) = 12.33\n",
      "Cumulative error: [1.23555556]\n",
      "error: 6 [1.23555556]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    90.    49.  2085.    21.7   80.     3.   299. ] pred_prototype adj [43.591]\n",
      "X_target [   4.    97.    69.  2265.    18.2   77.     3.   265. ] pred_target [25.69]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    90.    49.  2085.    21.7   80.     3.   299. ], f(x) = [43.591]\n",
      "Step 1: x = [   4.    90.    49.  2175.    21.7   80.     3.   299. ], f(x) = 42.64900000000003\n",
      "Step 2: x = [   4.    90.    49.  2175.    21.7   80.     3.   282. ], f(x) = 40.90500000000001\n",
      "Step 3: x = [   4.    97.    49.  2175.    21.7   80.     3.   282. ], f(x) = 39.11300000000001\n",
      "Step 4: x = [   4.    97.    49.  2175.    21.7   80.     3.   265. ], f(x) = 38.94800000000001\n",
      "Step 5: x = [   4.    97.    59.  2175.    21.7   80.     3.   265. ], f(x) = 38.006000000000014\n",
      "Cumulative error: [8.175]\n",
      "error: 7 [8.175]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.510e+02 8.900e+01 2.855e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02] pred_prototype adj [22.986]\n",
      "X_target [6.000e+00 2.250e+02 8.900e+01 3.264e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02] pred_target [19.573]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 8.900e+01 2.855e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02], f(x) = [22.986]\n",
      "Step 1: x = [4.000e+00 2.250e+02 8.900e+01 2.855e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02], f(x) = 21.325000000000003\n",
      "Step 2: x = [4.000e+00 2.250e+02 8.900e+01 3.264e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02], f(x) = 20.366000000000003\n",
      "Step 3: x = [6.000e+00 2.250e+02 8.900e+01 3.264e+03 1.600e+01 7.500e+01 1.000e+00\n",
      " 2.340e+02], f(x) = 19.573\n",
      "Cumulative error: [3.88266667]\n",
      "error: 8 [3.88266667]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.000e+00 6.800e+01 5.000e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] pred_prototype adj [42.914]\n",
      "X_target [   4.    68.    50.  1867.    19.5   73.     2.   123. ] pred_target [31.713]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 6.800e+01 5.000e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = [42.914]\n",
      "Step 1: x = [   4.    68.    50.  1976.    21.7   80.     2.   299. ], f(x) = 41.299000000000014\n",
      "Step 2: x = [   4.    68.    50.  1867.    21.7   80.     2.   299. ], f(x) = 41.15900000000001\n",
      "Step 3: x = [   4.    68.    50.  1867.    21.7   80.     2.   123. ], f(x) = 39.252999999999986\n",
      "Step 4: x = [   4.    68.    50.  1867.    19.5   80.     2.   123. ], f(x) = 37.98099999999999\n",
      "Step 5: x = [   4.    68.    50.  1867.    19.5   73.     2.   123. ], f(x) = 31.713\n",
      "Cumulative error: [19.52866667]\n",
      "error: 9 [19.52866667]\n",
      "X_proto [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02] org_proto [10.456]\n",
      "X_proto [8.000e+00 3.900e+02 3.800e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.000e+00] pred_prototype adj [11.601]\n",
      "X_target [8.00e+00 3.90e+02 3.80e+01 3.85e+03 8.50e+00 7.00e+01 1.00e+00 1.00e+00] pred_target [14.525]\n",
      "Found a path:\n",
      "Step 0: x = [8.000e+00 3.900e+02 3.800e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.000e+00], f(x) = [11.601]\n",
      "Step 1: x = [8.00e+00 3.90e+02 3.80e+01 3.85e+03 1.85e+01 7.00e+01 1.00e+00 1.00e+00], f(x) = 14.210999999999999\n",
      "Step 2: x = [8.00e+00 3.90e+02 3.80e+01 3.85e+03 8.50e+00 7.00e+01 1.00e+00 1.00e+00], f(x) = 14.525\n",
      "Cumulative error: [2.77122222]\n",
      "error: 10 [2.77122222]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [   4.   156.     5.  2930.    15.5   76.     3.   272. ] pred_prototype adj [20.81]\n",
      "X_target [   6.   156.     5.  2930.    15.5   76.     3.   272. ] pred_target [20.104]\n",
      "Found a path:\n",
      "Step 0: x = [   4.   156.     5.  2930.    15.5   76.     3.   272. ], f(x) = [20.81]\n",
      "Step 1: x = [   5.   156.     5.  2930.    15.5   76.     3.   272. ], f(x) = 20.754\n",
      "Step 2: x = [   6.   156.     5.  2930.    15.5   76.     3.   272. ], f(x) = 20.104\n",
      "Cumulative error: [1.20844444]\n",
      "error: 11 [1.20844444]\n",
      "X_proto [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02] org_proto [10.456]\n",
      "X_proto [8.000e+00 3.500e+02 3.000e+01 4.732e+03 1.490e+01 7.000e+01 1.000e+00\n",
      " 2.900e+01] pred_prototype adj [11.83]\n",
      "X_target [8.00e+00 3.50e+02 3.00e+01 4.36e+03 1.49e+01 7.90e+01 1.00e+00 2.90e+01] pred_target [17.072]\n",
      "Found a path:\n",
      "Step 0: x = [8.000e+00 3.500e+02 3.000e+01 4.732e+03 1.490e+01 7.000e+01 1.000e+00\n",
      " 2.900e+01], f(x) = [11.83]\n",
      "Step 1: x = [8.000e+00 3.500e+02 3.000e+01 4.732e+03 1.490e+01 7.900e+01 1.000e+00\n",
      " 2.900e+01], f(x) = 16.692000000000004\n",
      "Step 2: x = [8.00e+00 3.50e+02 3.00e+01 4.36e+03 1.49e+01 7.90e+01 1.00e+00 2.90e+01], f(x) = 17.072\n",
      "Cumulative error: [5.23344444]\n",
      "error: 12 [5.23344444]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    90.    49.  2085.    21.7   80.     3.   299. ] pred_prototype adj [43.591]\n",
      "X_target [   4.   97.   69. 2171.   16.   75.    3.  262.] pred_target [27.216]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    90.    49.  2085.    21.7   80.     3.   299. ], f(x) = [43.591]\n",
      "Step 1: x = [   4.    90.    49.  2128.    21.7   80.     3.   299. ], f(x) = 43.50700000000003\n",
      "Step 2: x = [   4.    90.    49.  2128.    21.7   80.     3.   280.5], f(x) = 41.71800000000001\n",
      "Step 3: x = [   4.    90.    49.  2171.    21.7   80.     3.   280.5], f(x) = 40.808000000000014\n",
      "Step 4: x = [   4.    93.5   49.  2171.    21.7   80.     3.   280.5], f(x) = 40.24600000000001\n",
      "Step 5: x = [   4.    93.5   59.  2171.    21.7   80.     3.   280.5], f(x) = 39.09600000000001\n",
      "Cumulative error: [5.52755556]\n",
      "error: 13 [5.52755556]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.630e+02 1.700e+01 2.855e+03 1.580e+01 7.800e+01 2.000e+00\n",
      " 2.120e+02] pred_prototype adj [22.902]\n",
      "X_target [6.00e+00 1.63e+02 1.70e+01 3.41e+03 1.58e+01 7.80e+01 2.00e+00 2.12e+02] pred_target [20.304]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.630e+02 1.700e+01 2.855e+03 1.580e+01 7.800e+01 2.000e+00\n",
      " 2.120e+02], f(x) = [22.902]\n",
      "Step 1: x = [4.0000e+00 1.6300e+02 1.7000e+01 3.1325e+03 1.5800e+01 7.8000e+01\n",
      " 2.0000e+00 2.1200e+02], f(x) = 21.012999999999998\n",
      "Step 2: x = [6.0000e+00 1.6300e+02 1.7000e+01 3.1325e+03 1.5800e+01 7.8000e+01\n",
      " 2.0000e+00 2.1200e+02], f(x) = 20.327999999999996\n",
      "Step 3: x = [6.00e+00 1.63e+02 1.70e+01 3.41e+03 1.58e+01 7.80e+01 2.00e+00 2.12e+02], f(x) = 20.304\n",
      "Cumulative error: [4.04266667]\n",
      "error: 14 [4.04266667]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.120e+02 8.200e+01 2.855e+03 1.960e+01 7.800e+01 1.000e+00\n",
      " 4.400e+01] pred_prototype adj [23.407]\n",
      "X_target [4.000e+00 1.120e+02 8.200e+01 2.605e+03 1.960e+01 8.200e+01 1.000e+00\n",
      " 4.400e+01] pred_target [30.061]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.120e+02 8.200e+01 2.855e+03 1.960e+01 7.800e+01 1.000e+00\n",
      " 4.400e+01], f(x) = [23.407]\n",
      "Step 1: x = [4.000e+00 1.120e+02 8.200e+01 2.605e+03 1.960e+01 7.800e+01 1.000e+00\n",
      " 4.400e+01], f(x) = 24.72200000000001\n",
      "Step 2: x = [4.000e+00 1.120e+02 8.200e+01 2.605e+03 1.960e+01 8.200e+01 1.000e+00\n",
      " 4.400e+01], f(x) = 30.061000000000014\n",
      "Cumulative error: [18.73288889]\n",
      "error: 15 [18.73288889]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.980e+02 8.900e+01 2.855e+03 1.650e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02] pred_prototype adj [22.723]\n",
      "X_target [6.000e+00 1.980e+02 8.900e+01 3.102e+03 1.650e+01 7.400e+01 1.000e+00\n",
      " 2.180e+02] pred_target [20.052]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.980e+02 8.900e+01 2.855e+03 1.650e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02], f(x) = [22.723]\n",
      "Step 1: x = [4.0000e+00 1.9800e+02 8.9000e+01 2.9785e+03 1.6500e+01 7.8000e+01\n",
      " 1.0000e+00 2.1800e+02], f(x) = 21.990999999999996\n",
      "Step 2: x = [4.000e+00 1.980e+02 8.900e+01 3.102e+03 1.650e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 21.766999999999992\n",
      "Step 3: x = [5.000e+00 1.980e+02 8.900e+01 3.102e+03 1.650e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 21.674999999999997\n",
      "Step 4: x = [5.000e+00 1.980e+02 8.900e+01 3.102e+03 1.650e+01 7.400e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 20.601999999999997\n",
      "Step 5: x = [6.000e+00 1.980e+02 8.900e+01 3.102e+03 1.650e+01 7.400e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 20.052\n",
      "Cumulative error: [3.55377778]\n",
      "error: 16 [3.55377778]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    90.    49.  2085.    21.7   81.     3.   299. ] pred_prototype adj [43.097]\n",
      "X_target [   4.   108.    69.  2350.    16.8   81.     3.   262. ] pred_target [32.596]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    90.    49.  2085.    21.7   81.     3.   299. ], f(x) = [43.097]\n",
      "Step 1: x = [   4.    90.    49.  2085.    16.8   81.     3.   299. ], f(x) = 39.973\n",
      "Step 2: x = [   4.    90.    49.  2085.    16.8   81.     3.   280.5], f(x) = 37.61099999999998\n",
      "Step 3: x = [   4.    90.    59.  2085.    16.8   81.     3.   280.5], f(x) = 36.431\n",
      "Step 4: x = [   4.    90.    59.  2350.    16.8   81.     3.   280.5], f(x) = 34.26900000000002\n",
      "Step 5: x = [   4.    90.    69.  2350.    16.8   81.     3.   280.5], f(x) = 34.183000000000014\n",
      "Cumulative error: [8.81255556]\n",
      "error: 17 [8.81255556]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.210e+02 7.400e+01 2.855e+03 1.500e+01 7.800e+01 1.000e+00\n",
      " 1.400e+01] pred_prototype adj [23.682]\n",
      "X_target [4.00e+00 1.21e+02 7.40e+01 2.67e+03 1.50e+01 7.90e+01 1.00e+00 1.40e+01] pred_target [29.929]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.210e+02 7.400e+01 2.855e+03 1.500e+01 7.800e+01 1.000e+00\n",
      " 1.400e+01], f(x) = [23.682]\n",
      "Step 1: x = [4.00e+00 1.21e+02 7.40e+01 2.67e+03 1.50e+01 7.80e+01 1.00e+00 1.40e+01], f(x) = 25.057000000000016\n",
      "Step 2: x = [4.00e+00 1.21e+02 7.40e+01 2.67e+03 1.50e+01 7.90e+01 1.00e+00 1.40e+01], f(x) = 29.929000000000023\n",
      "Cumulative error: [12.452]\n",
      "error: 18 [12.452]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.220e+02 8.200e+01 2.855e+03 1.510e+01 7.800e+01 2.000e+00\n",
      " 2.760e+02] pred_prototype adj [23.673]\n",
      "X_target [4.00e+00 1.22e+02 8.20e+01 2.50e+03 1.51e+01 8.00e+01 2.00e+00 2.76e+02] pred_target [30.434]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.220e+02 8.200e+01 2.855e+03 1.510e+01 7.800e+01 2.000e+00\n",
      " 2.760e+02], f(x) = [23.673]\n",
      "Step 1: x = [4.00e+00 1.22e+02 8.20e+01 2.50e+03 1.51e+01 7.80e+01 2.00e+00 2.76e+02], f(x) = 26.710000000000008\n",
      "Step 2: x = [4.00e+00 1.22e+02 8.20e+01 2.50e+03 1.51e+01 8.00e+01 2.00e+00 2.76e+02], f(x) = 30.434000000000005\n",
      "Cumulative error: [9.33988889]\n",
      "error: 19 [9.33988889]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.980e+02 8.900e+01 2.833e+03 1.550e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02] pred_prototype adj [22.759]\n",
      "X_target [6.000e+00 1.980e+02 8.900e+01 2.833e+03 1.550e+01 7.000e+01 1.000e+00\n",
      " 2.180e+02] pred_target [21.202]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.980e+02 8.900e+01 2.833e+03 1.550e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02], f(x) = [22.759]\n",
      "Step 1: x = [6.000e+00 1.980e+02 8.900e+01 2.833e+03 1.550e+01 7.800e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 21.884\n",
      "Step 2: x = [6.000e+00 1.980e+02 8.900e+01 2.833e+03 1.550e+01 7.000e+01 1.000e+00\n",
      " 2.180e+02], f(x) = 21.201999999999998\n",
      "Cumulative error: [3.44144444]\n",
      "error: 20 [3.44144444]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.00e+00 9.00e+01 5.10e+01 2.13e+03 2.46e+01 8.20e+01 2.00e+00 2.97e+02] pred_prototype adj [42.634]\n",
      "X_target [4.00e+00 9.70e+01 5.10e+01 2.13e+03 2.46e+01 8.20e+01 2.00e+00 2.97e+02] pred_target [41.22]\n",
      "Found a path:\n",
      "Step 0: x = [4.00e+00 9.00e+01 5.10e+01 2.13e+03 2.46e+01 8.20e+01 2.00e+00 2.97e+02], f(x) = [42.634]\n",
      "Step 1: x = [4.00e+00 9.70e+01 5.10e+01 2.13e+03 2.46e+01 8.20e+01 2.00e+00 2.97e+02], f(x) = 41.22000000000002\n",
      "Cumulative error: [1.766]\n",
      "error: 21 [1.766]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    91.    49.  2085.    21.7   81.     3.   299. ] pred_prototype adj [42.475]\n",
      "X_target [   4.   91.   63. 1985.   16.   81.    3.  175.] pred_target [33.468]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    91.    49.  2085.    21.7   81.     3.   299. ], f(x) = [42.475]\n",
      "Step 1: x = [   4.    91.    49.  2035.    21.7   81.     3.   299. ], f(x) = 41.64900000000002\n",
      "Step 2: x = [   4.    91.    49.  2035.    21.7   81.     3.   175. ], f(x) = 39.60899999999999\n",
      "Step 3: x = [   4.    91.    63.  2035.    21.7   81.     3.   175. ], f(x) = 37.541000000000004\n",
      "Step 4: x = [   4.    91.    63.  1985.    21.7   81.     3.   175. ], f(x) = 37.089\n",
      "Step 5: x = [   4.   91.   63. 1985.   16.   81.    3.  175.], f(x) = 33.468\n",
      "Cumulative error: [11.42977778]\n",
      "error: 22 [11.42977778]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.510e+02 1.500e+01 2.855e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 4.800e+01] pred_prototype adj [23.52]\n",
      "X_target [8.000e+00 3.070e+02 1.500e+01 3.504e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 4.800e+01] pred_target [16.186]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 1.500e+01 2.855e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 4.800e+01], f(x) = [23.52]\n",
      "Step 1: x = [8.000e+00 1.510e+02 1.500e+01 2.855e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 4.800e+01], f(x) = 22.731999999999992\n",
      "Step 2: x = [8.000e+00 1.510e+02 1.500e+01 2.855e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 4.800e+01], f(x) = 21.426\n",
      "Step 3: x = [8.000e+00 3.070e+02 1.500e+01 2.855e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 4.800e+01], f(x) = 16.667\n",
      "Step 4: x = [8.000e+00 3.070e+02 1.500e+01 3.504e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 4.800e+01], f(x) = 16.186\n",
      "Cumulative error: [13.29611111]\n",
      "error: 23 [13.29611111]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.000e+00 7.900e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] pred_prototype adj [42.956]\n",
      "X_target [   4.    79.    62.  1963.    15.5   74.     2.   280. ] pred_target [30.514]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2271961/2013005964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_search_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2271961/441000731.py\u001b[0m in \u001b[0;36mrun_search_path\u001b[0;34m(prototypes, X_target, partitions, max_steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_target\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred_target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# result = dfs(initial_state, [initial_x], [f_proto], 0.0, grid, max_steps, monotonic_increasing, tol=1e-6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_star_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonotonic_increasing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2271961/800947228.py\u001b[0m in \u001b[0;36ma_star_search\u001b[0;34m(initial_state, initial_x, f_proto, target_x, f_target, grid, max_steps, monotonic_increasing, tol)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0;31m# Compute heuristic from new state to target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0;31m# new_est_cost = new_cum_error + h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2271961/800947228.py\u001b[0m in \u001b[0;36mheuristic\u001b[0;34m(current_x, target_x, current_f, target_f, num_samples)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0madmissible\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreasonably\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_linear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0ma_star_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonotonic_increasing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n",
      "\u001b[0;32m/tmp/ipykernel_2271961/800947228.py\u001b[0m in \u001b[0;36mlocal_linear_error\u001b[0;34m(x_start, x_end, f_start, f_end, num_samples)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx_interp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mf_interp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mf_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_interp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0merror_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_actual\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf_interp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2271961/1477301080.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 289\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0mcomplains\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \"\"\"\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# Classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \"\"\"\n\u001b[0;32m--> 973\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_estimator_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prototypes = X_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "Errors = []\n",
    "No_path_index = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    if i==48:\n",
    "        continue\n",
    "    if i==70:\n",
    "        continue\n",
    "    error = run_search_path(prototypes,X_test.iloc[i].values)\n",
    "    print(\"error:\",i, error)\n",
    "    if error is not None:\n",
    "        Errors.append(error)\n",
    "    else:\n",
    "        No_path_index.append(i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34623458])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Errors).mean() / preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cylinders          4.0\n",
       "displacement     113.0\n",
       "horsepower        89.0\n",
       "weight          2278.0\n",
       "acceleration      15.5\n",
       "model year        72.0\n",
       "origin             3.0\n",
       "car name         268.0\n",
       "Name: 57, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_one_step(prototypes, f, X_target, avg_abs_pred, num_points=10):\n",
    "    \"\"\"\n",
    "    Baseline 1: Linear Model with Fixed Intercept fitted using inserted data.\n",
    "    \n",
    "    This function selects the prototype closest to X_target, then generates a set\n",
    "    of interpolation points between that prototype (x_start) and X_target (x_end). \n",
    "    It fits a linear model with the intercept fixed to f(x_start) (i.e., the function \n",
    "    value at the prototype) by estimating the slope using least squares on all inserted points.\n",
    "    The predicted endpoint is computed as f(x_start) + slope, and the cumulative error \n",
    "    is calculated using the linear_approximation_error function.\n",
    "    \n",
    "    Args:\n",
    "        prototypes (np.ndarray): Array of prototype instances.\n",
    "        f (callable): Function to evaluate.\n",
    "        X_target (np.ndarray): Target instance.\n",
    "        avg_abs_pred (float): Average absolute prediction value for normalization.\n",
    "        num_points (int): Number of interpolation points.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (raw_cumulative_error, normalized_cumulative_error)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Select the closest prototype to X_target.\n",
    "    distances = np.linalg.norm(prototypes - X_target, axis=1)\n",
    "    closest_proto_index = np.argmin(distances)\n",
    "    x_start = prototypes[closest_proto_index]\n",
    "    x_end = X_target\n",
    "    \n",
    "    # Generate trajectory of points between X_proto and X_target.\n",
    "    path = np.array([x_start + (x_end - x_start) * (i / (num_points - 1)) for i in range(num_points)])\n",
    "    \n",
    "    # Evaluate the function on the trajectory.\n",
    "    f_values = np.array([f(x) for x in path])\n",
    "    \n",
    "    X_features = path - x_start              # shape: (num_points, d)\n",
    "    Y_targets = f_values - f_values[0]         # shape: (num_points,)\n",
    "    w, residuals, rank, s = np.linalg.lstsq(X_features, Y_targets, rcond=None)\n",
    "    predictions = f_values[0] + np.dot((path - x_start), w)\n",
    "\n",
    "    # Cumulative absolute error\n",
    "    raw_cumulative_error = np.sum(np.abs(f_values - predictions))\n",
    "    normalized_cumulative_error = raw_cumulative_error / avg_abs_pred\n",
    "    \n",
    "    errors = np.abs(f_values - predictions)\n",
    "    \n",
    "    \n",
    "    # print(\"Linear Model Fitted using Inserted Data:\")\n",
    "    # for i, (x_val, actual, pred) in enumerate(zip(path, f_values, predictions)):\n",
    "    #     print(f\"Step {i}: x = {x_val}, f(x) = {actual}, prediction = {pred}\")\n",
    "    print(\"Raw Cumulative Error:\", raw_cumulative_error)\n",
    "    print(\"error:\",errors)\n",
    "    print(\"Normalized Cumulative Error:\", normalized_cumulative_error)\n",
    "    \n",
    "    return raw_cumulative_error, normalized_cumulative_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline1run(prototypes, X_target, avg_abs_pred, num_points=10):\n",
    "    \"\"\"\n",
    "    Baseline 1: Linear Interpolation.\n",
    "    \n",
    "    Constructs a straight-line trajectory between the closest prototype (to X_target)\n",
    "    and the target instance. The trajectory consists of num_points evenly spaced points.\n",
    "    The cumulative error is computed as the sum of absolute differences between the \n",
    "    function values along the trajectory and f(X_target). The error is then normalized.\n",
    "    \n",
    "    Args:\n",
    "        prototypes (np.ndarray): Array of prototype instances.\n",
    "        X_target (np.ndarray): Target instance.\n",
    "        avg_abs_pred (float): Average absolute prediction value for normalization.\n",
    "        num_points (int): Number of interpolation points.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (raw_cumulative_error, normalized_cumulative_error)\n",
    "    \"\"\"\n",
    "    # Select the closest prototype to X_target.\n",
    "    distances = np.linalg.norm(prototypes - X_target, axis=1)\n",
    "    closest_proto_index = np.argmin(distances)\n",
    "    X_proto = prototypes[closest_proto_index]\n",
    "    \n",
    "    # Create the linear interpolation trajectory.\n",
    "    path = [X_proto + (X_target - X_proto) * (i / (num_points - 1)) for i in range(num_points)]\n",
    "    \n",
    "    f_target = f(X_target)\n",
    "    f_values = [f(x) for x in path]\n",
    "    \n",
    "    # Compute the cumulative error along the trajectory.\n",
    "    raw_cumulative_error = sum(abs(val - f_target) for val in f_values)\n",
    "    normalized_cumulative_error = raw_cumulative_error / avg_abs_pred\n",
    "    \n",
    "    print(\"Linear Interpolation (Baseline 1) Path:\")\n",
    "    for i, (x_val, fx_val) in enumerate(zip(path, f_values)):\n",
    "        print(f\"Step {i}: x = {x_val}, f(x) = {fx_val}\")\n",
    "    print(\"Raw Cumulative Error:\", raw_cumulative_error)\n",
    "    print(\"Normalized Cumulative Error:\", normalized_cumulative_error)\n",
    "    \n",
    "    return raw_cumulative_error, normalized_cumulative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Cumulative Error: 19.78274736842107\n",
      "error: [[0.        ]\n",
      " [0.13908421]\n",
      " [0.63216842]\n",
      " [5.91425263]\n",
      " [4.57733684]\n",
      " [2.19242105]\n",
      " [0.46050526]\n",
      " [0.02441053]\n",
      " [1.57332632]\n",
      " [4.26924211]]\n",
      "Normalized Cumulative Error: 0.8553058253906547\n",
      "error: 0 19.78274736842107\n",
      "Raw Cumulative Error: 0.8674666666666759\n",
      "error: [[0.        ]\n",
      " [0.08707719]\n",
      " [0.21815439]\n",
      " [0.05223158]\n",
      " [0.02530877]\n",
      " [0.03338596]\n",
      " [0.23253684]\n",
      " [0.08945965]\n",
      " [0.09061754]\n",
      " [0.03869474]]\n",
      "Normalized Cumulative Error: 0.03750486621067531\n",
      "error: 1 0.8674666666666759\n",
      "Raw Cumulative Error: 13.478196491228246\n",
      "error: [[0.        ]\n",
      " [1.43010877]\n",
      " [1.36921754]\n",
      " [3.62132632]\n",
      " [2.01543509]\n",
      " [1.32654386]\n",
      " [0.05865263]\n",
      " [0.1107614 ]\n",
      " [1.06112982]\n",
      " [2.48502105]]\n",
      "Normalized Cumulative Error: 0.5827289688341953\n",
      "error: 2 13.478196491228246\n",
      "Raw Cumulative Error: 25.200715789473872\n",
      "error: [[0.        ]\n",
      " [1.00009474]\n",
      " [1.82518947]\n",
      " [5.98328421]\n",
      " [4.95037895]\n",
      " [2.89747368]\n",
      " [1.09756842]\n",
      " [0.54633684]\n",
      " [2.45324211]\n",
      " [4.44714737]]\n",
      "Normalized Cumulative Error: 1.0895513457932602\n",
      "error: 3 25.200715789473872\n",
      "Raw Cumulative Error: 7.666754385964953\n",
      "error: [[0.        ]\n",
      " [0.54415088]\n",
      " [1.56169825]\n",
      " [1.01154737]\n",
      " [1.45339649]\n",
      " [0.88424561]\n",
      " [0.21809474]\n",
      " [0.15105614]\n",
      " [0.48320702]\n",
      " [1.35935789]]\n",
      "Normalized Cumulative Error: 0.3314716386978027\n",
      "error: 4 7.666754385964953\n",
      "Raw Cumulative Error: 6.565421052631564\n",
      "error: [[0.        ]\n",
      " [0.89168421]\n",
      " [0.11936842]\n",
      " [0.27994737]\n",
      " [0.22626316]\n",
      " [0.71542105]\n",
      " [2.32289474]\n",
      " [0.44021053]\n",
      " [0.07047368]\n",
      " [1.49915789]]\n",
      "Normalized Cumulative Error: 0.2838555620147116\n",
      "error: 5 6.565421052631564\n",
      "Raw Cumulative Error: 1.313483154296872\n",
      "error: [[0.        ]\n",
      " [0.01713013]\n",
      " [0.24094629]\n",
      " [0.17227539]\n",
      " [0.15925293]\n",
      " [0.06355859]\n",
      " [0.24378516]\n",
      " [0.12088477]\n",
      " [0.03122217]\n",
      " [0.26442773]]\n",
      "Normalized Cumulative Error: 0.05678836071151181\n",
      "error: 6 1.313483154296872\n",
      "Raw Cumulative Error: 6.3313333333332515\n",
      "error: [[0.        ]\n",
      " [1.08166667]\n",
      " [0.46133333]\n",
      " [1.533     ]\n",
      " [0.37466667]\n",
      " [0.21666667]\n",
      " [0.417     ]\n",
      " [0.58433333]\n",
      " [1.19966667]\n",
      " [0.463     ]]\n",
      "Normalized Cumulative Error: 0.2737347943458154\n",
      "error: 7 6.3313333333332515\n",
      "Raw Cumulative Error: 2.653136842105269\n",
      "error: [[0.        ]\n",
      " [0.03720702]\n",
      " [0.58241404]\n",
      " [0.41362105]\n",
      " [0.18282807]\n",
      " [0.17996491]\n",
      " [0.54375789]\n",
      " [0.26455088]\n",
      " [0.40465614]\n",
      " [0.04413684]]\n",
      "Normalized Cumulative Error: 0.11470820277640327\n",
      "error: 8 2.653136842105269\n",
      "Raw Cumulative Error: 21.695968421052793\n",
      "error: [[0.        ]\n",
      " [2.39034386]\n",
      " [2.72668772]\n",
      " [1.49803158]\n",
      " [4.47137544]\n",
      " [3.2517193 ]\n",
      " [1.09406316]\n",
      " [0.57959298]\n",
      " [2.16824912]\n",
      " [3.51590526]]\n",
      "Normalized Cumulative Error: 0.9380238160266823\n",
      "error: 9 21.695968421052793\n",
      "Raw Cumulative Error: 3.0086315789473694\n",
      "error: [[0.        ]\n",
      " [0.01777544]\n",
      " [0.45155088]\n",
      " [0.43932632]\n",
      " [0.58289825]\n",
      " [0.65512281]\n",
      " [0.27234737]\n",
      " [0.03542807]\n",
      " [0.23320351]\n",
      " [0.32097895]]\n",
      "Normalized Cumulative Error: 0.13007799513406781\n",
      "error: 10 3.0086315789473694\n",
      "Raw Cumulative Error: 2.7141929824561117\n",
      "error: [[0.        ]\n",
      " [0.0040386 ]\n",
      " [0.40492281]\n",
      " [0.01088421]\n",
      " [0.43784561]\n",
      " [0.45080702]\n",
      " [0.48976842]\n",
      " [0.04827018]\n",
      " [0.36430877]\n",
      " [0.50334737]]\n",
      "Normalized Cumulative Error: 0.11734796112469548\n",
      "error: 11 2.7141929824561117\n",
      "Raw Cumulative Error: 2.4880385964912186\n",
      "error: [[0.        ]\n",
      " [0.03529123]\n",
      " [0.49058246]\n",
      " [0.69587368]\n",
      " [0.44716491]\n",
      " [0.29254386]\n",
      " [0.09225263]\n",
      " [0.0380386 ]\n",
      " [0.39467018]\n",
      " [0.00162105]]\n",
      "Normalized Cumulative Error: 0.10757019061835058\n",
      "error: 12 2.4880385964912186\n",
      "Raw Cumulative Error: 10.053263157894772\n",
      "error: [[0.        ]\n",
      " [0.73908772]\n",
      " [1.07917544]\n",
      " [0.94726316]\n",
      " [0.39264912]\n",
      " [2.5684386 ]\n",
      " [0.86852632]\n",
      " [0.52561404]\n",
      " [0.49129825]\n",
      " [2.44121053]]\n",
      "Normalized Cumulative Error: 0.4346521938028941\n",
      "error: 13 10.053263157894772\n",
      "Raw Cumulative Error: 1.896126315789484\n",
      "error: [[0.        ]\n",
      " [0.18629123]\n",
      " [0.22358246]\n",
      " [0.04287368]\n",
      " [0.20683509]\n",
      " [0.18154386]\n",
      " [0.37525263]\n",
      " [0.5240386 ]\n",
      " [0.05632982]\n",
      " [0.09937895]]\n",
      "Normalized Cumulative Error: 0.08197890077492835\n",
      "error: 14 1.896126315789484\n",
      "Raw Cumulative Error: 5.942642105263154\n",
      "error: [[0.        ]\n",
      " [0.79145263]\n",
      " [0.77809474]\n",
      " [0.38935789]\n",
      " [1.09018947]\n",
      " [0.81773684]\n",
      " [0.50428421]\n",
      " [0.15283158]\n",
      " [0.62662105]\n",
      " [0.79207368]]\n",
      "Normalized Cumulative Error: 0.2569297537993599\n",
      "error: 15 5.942642105263154\n",
      "Raw Cumulative Error: 1.4227894736842153\n",
      "error: [[0.        ]\n",
      " [0.09736842]\n",
      " [0.13126316]\n",
      " [0.17410526]\n",
      " [0.24547368]\n",
      " [0.10615789]\n",
      " [0.19721053]\n",
      " [0.10557895]\n",
      " [0.03294737]\n",
      " [0.33268421]]\n",
      "Normalized Cumulative Error: 0.06151421248441791\n",
      "error: 16 1.4227894736842153\n",
      "Raw Cumulative Error: 12.398021052631591\n",
      "error: [[0.        ]\n",
      " [0.56089123]\n",
      " [0.91978246]\n",
      " [2.27532632]\n",
      " [1.03743509]\n",
      " [2.72454386]\n",
      " [1.36365263]\n",
      " [0.1632386 ]\n",
      " [0.94112982]\n",
      " [2.41202105]]\n",
      "Normalized Cumulative Error: 0.536027652385581\n",
      "error: 17 12.398021052631591\n",
      "Raw Cumulative Error: 7.821754385964894\n",
      "error: [[0.        ]\n",
      " [0.61652982]\n",
      " [1.43105965]\n",
      " [1.85358947]\n",
      " [1.6961193 ]\n",
      " [0.55935088]\n",
      " [0.31182105]\n",
      " [0.18529123]\n",
      " [0.6527614 ]\n",
      " [0.51523158]]\n",
      "Normalized Cumulative Error: 0.33817305384841645\n",
      "error: 18 7.821754385964894\n",
      "Raw Cumulative Error: 4.137494736842093\n",
      "error: [[0.00000000e+00]\n",
      " [8.34056140e-01]\n",
      " [8.48112281e-01]\n",
      " [6.08831579e-01]\n",
      " [2.45775439e-01]\n",
      " [3.55719298e-01]\n",
      " [3.36842105e-04]\n",
      " [3.59607018e-01]\n",
      " [1.99550877e-01]\n",
      " [6.85505263e-01]]\n",
      "Normalized Cumulative Error: 0.1788843220327017\n",
      "error: 19 4.137494736842093\n",
      "Raw Cumulative Error: 1.3251411132812585\n",
      "error: [[0.        ]\n",
      " [0.05930469]\n",
      " [0.0093418 ]\n",
      " [0.28091016]\n",
      " [0.25319141]\n",
      " [0.12847266]\n",
      " [0.15426563]\n",
      " [0.10189844]\n",
      " [0.01632178]\n",
      " [0.32143457]]\n",
      "Normalized Cumulative Error: 0.05729239182740362\n",
      "error: 20 1.3251411132812585\n",
      "Raw Cumulative Error: 1.8772035087719559\n",
      "error: [[0.        ]\n",
      " [0.21670877]\n",
      " [0.10558246]\n",
      " [0.16212632]\n",
      " [0.14216491]\n",
      " [0.00645614]\n",
      " [0.50425263]\n",
      " [0.2269614 ]\n",
      " [0.11132982]\n",
      " [0.40162105]]\n",
      "Normalized Cumulative Error: 0.08116077441596414\n",
      "error: 21 1.8772035087719559\n",
      "Raw Cumulative Error: 8.401105263158115\n",
      "error: [[0.        ]\n",
      " [1.22805965]\n",
      " [2.3621193 ]\n",
      " [1.69417895]\n",
      " [0.8972386 ]\n",
      " [0.13729825]\n",
      " [0.77964211]\n",
      " [0.38158246]\n",
      " [0.32752281]\n",
      " [0.59346316]]\n",
      "Normalized Cumulative Error: 0.3632212522093551\n",
      "error: 22 8.401105263158115\n",
      "Raw Cumulative Error: 4.378747368421063\n",
      "error: [[0.        ]\n",
      " [0.48430526]\n",
      " [0.14538947]\n",
      " [0.14091579]\n",
      " [0.39722105]\n",
      " [0.66152632]\n",
      " [0.73283158]\n",
      " [1.17586316]\n",
      " [0.24044211]\n",
      " [0.40025263]]\n",
      "Normalized Cumulative Error: 0.18931486422876206\n",
      "error: 23 4.378747368421063\n",
      "Raw Cumulative Error: 19.216010526315834\n",
      "error: [[0.        ]\n",
      " [1.18066316]\n",
      " [1.41932632]\n",
      " [1.51598947]\n",
      " [4.88165263]\n",
      " [2.73331579]\n",
      " [1.53697895]\n",
      " [0.29335789]\n",
      " [1.96369474]\n",
      " [3.69103158]]\n",
      "Normalized Cumulative Error: 0.8308029940351936\n",
      "error: 24 19.216010526315834\n",
      "Raw Cumulative Error: 21.563505263158028\n",
      "error: [[0.        ]\n",
      " [2.08116491]\n",
      " [2.94132982]\n",
      " [0.67049474]\n",
      " [3.96665965]\n",
      " [3.84782456]\n",
      " [1.57798947]\n",
      " [0.42184561]\n",
      " [2.9096807 ]\n",
      " [3.14651579]]\n",
      "Normalized Cumulative Error: 0.9322967798123954\n",
      "error: 25 21.563505263158028\n",
      "Raw Cumulative Error: 1.803771929824567\n",
      "error: [[0.        ]\n",
      " [0.18584561]\n",
      " [0.01730877]\n",
      " [0.35753684]\n",
      " [0.20238246]\n",
      " [0.24122807]\n",
      " [0.00492632]\n",
      " [0.2419193 ]\n",
      " [0.07023509]\n",
      " [0.48238947]]\n",
      "Normalized Cumulative Error: 0.07798596476634022\n",
      "error: 26 1.803771929824567\n",
      "Raw Cumulative Error: 4.488894736842134\n",
      "error: [[0.        ]\n",
      " [0.68447368]\n",
      " [0.63294737]\n",
      " [0.54742105]\n",
      " [1.06489474]\n",
      " [0.31236842]\n",
      " [0.18015789]\n",
      " [0.46268421]\n",
      " [0.34121053]\n",
      " [0.26273684]]\n",
      "Normalized Cumulative Error: 0.1940770787031974\n",
      "error: 27 4.488894736842134\n",
      "Raw Cumulative Error: 15.181747368421096\n",
      "error: [[0.        ]\n",
      " [0.30974737]\n",
      " [0.10250526]\n",
      " [1.96475789]\n",
      " [3.62998947]\n",
      " [2.65773684]\n",
      " [2.15048421]\n",
      " [0.16723158]\n",
      " [1.70102105]\n",
      " [2.49827368]]\n",
      "Normalized Cumulative Error: 0.656381882758491\n",
      "error: 28 15.181747368421096\n",
      "Raw Cumulative Error: 4.8940350877192955\n",
      "error: [[0.        ]\n",
      " [0.16720702]\n",
      " [0.73358596]\n",
      " [0.64837895]\n",
      " [0.39517193]\n",
      " [0.63196491]\n",
      " [0.71475789]\n",
      " [0.77744912]\n",
      " [0.59765614]\n",
      " [0.22786316]]\n",
      "Normalized Cumulative Error: 0.21159329602896648\n",
      "error: 29 4.8940350877192955\n",
      "Raw Cumulative Error: 3.245473684210536\n",
      "error: [[0.        ]\n",
      " [0.31550175]\n",
      " [0.62100351]\n",
      " [0.03050526]\n",
      " [0.03899298]\n",
      " [0.21849123]\n",
      " [0.55798947]\n",
      " [0.36248772]\n",
      " [0.25998596]\n",
      " [0.84051579]]\n",
      "Normalized Cumulative Error: 0.1403178485051287\n",
      "error: 30 3.245473684210536\n",
      "Raw Cumulative Error: 2.1074982456140248\n",
      "error: [[0.        ]\n",
      " [0.22750175]\n",
      " [0.45100351]\n",
      " [0.25050526]\n",
      " [0.33999298]\n",
      " [0.17849123]\n",
      " [0.30098947]\n",
      " [0.22951228]\n",
      " [0.03498596]\n",
      " [0.09451579]]\n",
      "Normalized Cumulative Error: 0.09111755272938758\n",
      "error: 31 2.1074982456140248\n",
      "Raw Cumulative Error: 5.486284210526307\n",
      "error: [[0.        ]\n",
      " [0.68336491]\n",
      " [0.48972982]\n",
      " [0.02290526]\n",
      " [1.00445965]\n",
      " [0.45182456]\n",
      " [0.09081053]\n",
      " [0.54655439]\n",
      " [0.5069193 ]\n",
      " [1.68971579]]\n",
      "Normalized Cumulative Error: 0.23719914921940594\n",
      "error: 32 5.486284210526307\n",
      "Raw Cumulative Error: 5.733294736842119\n",
      "error: [[0.        ]\n",
      " [0.78518947]\n",
      " [0.98662105]\n",
      " [0.53943158]\n",
      " [0.31424211]\n",
      " [0.91805263]\n",
      " [0.29386316]\n",
      " [0.39567368]\n",
      " [0.31551579]\n",
      " [1.18470526]]\n",
      "Normalized Cumulative Error: 0.24787863362853163\n",
      "error: 33 5.733294736842119\n",
      "Raw Cumulative Error: 2.8873929824561397\n",
      "error: [[0.        ]\n",
      " [0.22335439]\n",
      " [0.66070877]\n",
      " [0.70006316]\n",
      " [0.44741754]\n",
      " [0.09922807]\n",
      " [0.08412632]\n",
      " [0.1725193 ]\n",
      " [0.26416491]\n",
      " [0.23581053]]\n",
      "Normalized Cumulative Error: 0.1248362521188047\n",
      "error: 34 2.8873929824561397\n",
      "Raw Cumulative Error: 8.218263157894988\n",
      "error: [[0.        ]\n",
      " [1.24491579]\n",
      " [1.16983158]\n",
      " [1.91074737]\n",
      " [1.16866316]\n",
      " [0.67757895]\n",
      " [0.01850526]\n",
      " [0.02258947]\n",
      " [0.93867368]\n",
      " [1.06675789]]\n",
      "Normalized Cumulative Error: 0.3553160854068977\n",
      "error: 35 8.218263157894988\n",
      "Raw Cumulative Error: 1.976368421052653\n",
      "error: [[0.        ]\n",
      " [0.04036842]\n",
      " [0.54926316]\n",
      " [0.17889474]\n",
      " [0.03147368]\n",
      " [0.10784211]\n",
      " [0.22821053]\n",
      " [0.42857895]\n",
      " [0.26605263]\n",
      " [0.14568421]]\n",
      "Normalized Cumulative Error: 0.08544816309704414\n",
      "error: 36 1.976368421052653\n",
      "Raw Cumulative Error: 27.387631578947474\n",
      "error: [[0.        ]\n",
      " [1.94945614]\n",
      " [1.45891228]\n",
      " [5.73136842]\n",
      " [4.89682456]\n",
      " [3.7162807 ]\n",
      " [1.50973684]\n",
      " [0.68680702]\n",
      " [2.46335088]\n",
      " [4.97489474]]\n",
      "Normalized Cumulative Error: 1.1841025109848755\n",
      "error: 37 27.387631578947474\n",
      "Raw Cumulative Error: 2.2177368421052694\n",
      "error: [[0.        ]\n",
      " [0.22173684]\n",
      " [0.39347368]\n",
      " [0.25521053]\n",
      " [0.01305263]\n",
      " [0.09731579]\n",
      " [0.30557895]\n",
      " [0.47384211]\n",
      " [0.20289474]\n",
      " [0.25463158]]\n",
      "Normalized Cumulative Error: 0.09588371144363986\n",
      "error: 38 2.2177368421052694\n",
      "Raw Cumulative Error: 1.3406105263157873\n",
      "error: [[0.        ]\n",
      " [0.13387368]\n",
      " [0.08225263]\n",
      " [0.11762105]\n",
      " [0.14850526]\n",
      " [0.27063158]\n",
      " [0.20675789]\n",
      " [0.24311579]\n",
      " [0.07698947]\n",
      " [0.06086316]]\n",
      "Normalized Cumulative Error: 0.05796121091695673\n",
      "error: 39 1.3406105263157873\n",
      "Raw Cumulative Error: 1.8554842105263134\n",
      "error: [[0.        ]\n",
      " [0.54841053]\n",
      " [0.14682105]\n",
      " [0.03076842]\n",
      " [0.02735789]\n",
      " [0.36894737]\n",
      " [0.31446316]\n",
      " [0.08712632]\n",
      " [0.17128421]\n",
      " [0.16030526]]\n",
      "Normalized Cumulative Error: 0.08022174193645382\n",
      "error: 40 1.8554842105263134\n",
      "Raw Cumulative Error: 18.798536842105356\n",
      "error: [[0.        ]\n",
      " [2.08695789]\n",
      " [1.49391579]\n",
      " [1.05487368]\n",
      " [4.43183158]\n",
      " [2.37178947]\n",
      " [1.74574737]\n",
      " [0.02670526]\n",
      " [1.79333684]\n",
      " [3.79337895]]\n",
      "Normalized Cumulative Error: 0.8127535458264731\n",
      "error: 41 18.798536842105356\n",
      "Raw Cumulative Error: 5.187119298245598\n",
      "error: [[0.        ]\n",
      " [0.0281193 ]\n",
      " [1.1817614 ]\n",
      " [1.24664211]\n",
      " [0.43852281]\n",
      " [0.32859649]\n",
      " [0.43628421]\n",
      " [0.30216491]\n",
      " [0.10595439]\n",
      " [1.11907368]]\n",
      "Normalized Cumulative Error: 0.22426477324720764\n",
      "error: 42 5.187119298245598\n",
      "Raw Cumulative Error: 20.19655087719314\n",
      "error: [[0.        ]\n",
      " [1.21832281]\n",
      " [1.73164561]\n",
      " [2.07296842]\n",
      " [3.95129123]\n",
      " [1.94061404]\n",
      " [2.38193684]\n",
      " [0.59625965]\n",
      " [1.85741754]\n",
      " [4.44609474]]\n",
      "Normalized Cumulative Error: 0.8731965937975149\n",
      "error: 43 20.19655087719314\n",
      "Raw Cumulative Error: 2.0117626953124983\n",
      "error: [[0.        ]\n",
      " [0.22118652]\n",
      " [0.54685547]\n",
      " [0.01216406]\n",
      " [0.11701562]\n",
      " [0.06219141]\n",
      " [0.35683594]\n",
      " [0.02896094]\n",
      " [0.27073633]\n",
      " [0.39581641]]\n",
      "Normalized Cumulative Error: 0.08697843229556024\n",
      "error: 44 2.0117626953124983\n",
      "Raw Cumulative Error: 2.1912127838134747\n",
      "error: [[0.        ]\n",
      " [0.03140991]\n",
      " [0.51326477]\n",
      " [0.51473381]\n",
      " [0.42616089]\n",
      " [0.07198141]\n",
      " [0.05340277]\n",
      " [0.03514154]\n",
      " [0.16327905]\n",
      " [0.38183862]]\n",
      "Normalized Cumulative Error: 0.09473694546884977\n",
      "error: 45 2.1912127838134747\n",
      "Raw Cumulative Error: 1.614392982456156\n",
      "error: [[0.        ]\n",
      " [0.34239298]\n",
      " [0.46878596]\n",
      " [0.09317895]\n",
      " [0.16557193]\n",
      " [0.19903509]\n",
      " [0.11335789]\n",
      " [0.00375088]\n",
      " [0.12185614]\n",
      " [0.10646316]]\n",
      "Normalized Cumulative Error: 0.06979817801084065\n",
      "error: 46 1.614392982456156\n",
      "Raw Cumulative Error: 7.89536140350878\n",
      "error: [[0.        ]\n",
      " [1.41295088]\n",
      " [1.13790175]\n",
      " [0.35414737]\n",
      " [1.39819649]\n",
      " [0.90875439]\n",
      " [0.58270526]\n",
      " [0.48565614]\n",
      " [0.35660702]\n",
      " [1.25844211]]\n",
      "Normalized Cumulative Error: 0.34135544857461175\n",
      "error: 47 7.89536140350878\n",
      "Raw Cumulative Error: 25.95790526315804\n",
      "error: [[0.        ]\n",
      " [2.23369825]\n",
      " [2.44639649]\n",
      " [0.32109474]\n",
      " [5.93179298]\n",
      " [4.67649123]\n",
      " [2.17318947]\n",
      " [0.75211228]\n",
      " [3.83441404]\n",
      " [3.58871579]]\n",
      "Normalized Cumulative Error: 1.1222883845728362\n",
      "error: 48 25.95790526315804\n",
      "Raw Cumulative Error: 11.36778947368428\n",
      "error: [[0.        ]\n",
      " [1.05957895]\n",
      " [2.07184211]\n",
      " [0.79426316]\n",
      " [1.05468421]\n",
      " [0.65010526]\n",
      " [2.12752632]\n",
      " [0.38194737]\n",
      " [0.67563158]\n",
      " [2.55221053]]\n",
      "Normalized Cumulative Error: 0.4914856555352529\n",
      "error: 49 11.36778947368428\n",
      "Raw Cumulative Error: 1.1020280701754341\n",
      "error: [[0.        ]\n",
      " [0.07474035]\n",
      " [0.0505193 ]\n",
      " [0.00822105]\n",
      " [0.2770386 ]\n",
      " [0.31229825]\n",
      " [0.13344211]\n",
      " [0.13218246]\n",
      " [0.07692281]\n",
      " [0.03666316]]\n",
      "Normalized Cumulative Error: 0.047646113586310226\n",
      "error: 50 1.1020280701754341\n",
      "Raw Cumulative Error: 25.461442105263373\n",
      "error: [[0.        ]\n",
      " [0.58118596]\n",
      " [3.43337193]\n",
      " [5.53955789]\n",
      " [5.65674386]\n",
      " [2.64092982]\n",
      " [0.29111579]\n",
      " [1.22969825]\n",
      " [1.76251228]\n",
      " [4.32632632]]\n",
      "Normalized Cumulative Error: 1.100823831488719\n",
      "error: 51 25.461442105263373\n",
      "Raw Cumulative Error: 29.71464561403522\n",
      "error: [[0.        ]\n",
      " [2.97178596]\n",
      " [3.73757193]\n",
      " [5.11235789]\n",
      " [5.64314386]\n",
      " [3.38192982]\n",
      " [0.20771579]\n",
      " [0.57550175]\n",
      " [2.22071228]\n",
      " [5.86392632]]\n",
      "Normalized Cumulative Error: 1.2847108149231579\n",
      "error: 52 29.71464561403522\n",
      "Raw Cumulative Error: 18.799810526315877\n",
      "error: [[0.        ]\n",
      " [1.04639649]\n",
      " [4.08279298]\n",
      " [1.93918947]\n",
      " [2.48858596]\n",
      " [3.20498246]\n",
      " [0.72537895]\n",
      " [0.40222456]\n",
      " [1.64682807]\n",
      " [3.26343158]]\n",
      "Normalized Cumulative Error: 0.8128086134823794\n",
      "error: 53 18.799810526315877\n",
      "Raw Cumulative Error: 9.230340350877224\n",
      "error: [[0.        ]\n",
      " [0.50352281]\n",
      " [1.71395439]\n",
      " [1.10943158]\n",
      " [1.17790877]\n",
      " [0.35161404]\n",
      " [0.93213684]\n",
      " [2.08865965]\n",
      " [1.17081754]\n",
      " [0.18229474]]\n",
      "Normalized Cumulative Error: 0.3990731785336355\n",
      "error: 54 9.230340350877224\n",
      "Raw Cumulative Error: 5.562610526315797\n",
      "error: [[0.        ]\n",
      " [0.23984561]\n",
      " [0.38269123]\n",
      " [0.17646316]\n",
      " [0.86161754]\n",
      " [1.56277193]\n",
      " [0.54592632]\n",
      " [0.5019193 ]\n",
      " [1.07576491]\n",
      " [0.21561053]]\n",
      "Normalized Cumulative Error: 0.24049911263245377\n",
      "error: 55 5.562610526315797\n",
      "Raw Cumulative Error: 4.186347368421057\n",
      "error: [[0.        ]\n",
      " [0.0519614 ]\n",
      " [0.40692281]\n",
      " [0.29611579]\n",
      " [0.18915439]\n",
      " [0.57319298]\n",
      " [0.83123158]\n",
      " [0.07972982]\n",
      " [1.40569123]\n",
      " [0.35234737]]\n",
      "Normalized Cumulative Error: 0.18099646245470646\n",
      "error: 56 4.186347368421057\n",
      "Raw Cumulative Error: 3.567063157894733\n",
      "error: [[0.        ]\n",
      " [0.03764211]\n",
      " [0.05028421]\n",
      " [0.02992632]\n",
      " [0.54556842]\n",
      " [0.75921053]\n",
      " [0.85785263]\n",
      " [0.00649474]\n",
      " [0.12186316]\n",
      " [1.15822105]]\n",
      "Normalized Cumulative Error: 0.15422174896465127\n",
      "error: 57 3.567063157894733\n",
      "Raw Cumulative Error: 31.610971929824714\n",
      "error: [[0.        ]\n",
      " [0.26127018]\n",
      " [0.44054035]\n",
      " [5.93881053]\n",
      " [5.1490807 ]\n",
      " [4.28735088]\n",
      " [3.75062105]\n",
      " [1.20889123]\n",
      " [3.2118386 ]\n",
      " [7.36256842]]\n",
      "Normalized Cumulative Error: 1.366698362685378\n",
      "error: 58 31.610971929824714\n",
      "Raw Cumulative Error: 26.38934736842123\n",
      "error: [[0.        ]\n",
      " [0.75755088]\n",
      " [3.32110175]\n",
      " [5.72165263]\n",
      " [4.93320351]\n",
      " [3.18275439]\n",
      " [0.76030526]\n",
      " [0.69614386]\n",
      " [3.24959298]\n",
      " [3.76704211]]\n",
      "Normalized Cumulative Error: 1.1409417565781557\n",
      "error: 59 26.38934736842123\n",
      "Raw Cumulative Error: 1.5241087719298214\n",
      "error: [[0.        ]\n",
      " [0.00371228]\n",
      " [0.44257544]\n",
      " [0.36286316]\n",
      " [0.31915088]\n",
      " [0.0054386 ]\n",
      " [0.00827368]\n",
      " [0.04698596]\n",
      " [0.12069825]\n",
      " [0.21441053]]\n",
      "Normalized Cumulative Error: 0.06589474590579156\n",
      "error: 60 1.5241087719298214\n",
      "Raw Cumulative Error: 2.616263157894739\n",
      "error: [[0.        ]\n",
      " [0.31910526]\n",
      " [0.12121053]\n",
      " [0.41731579]\n",
      " [0.08942105]\n",
      " [0.21247368]\n",
      " [0.56436842]\n",
      " [0.01626316]\n",
      " [0.32315789]\n",
      " [0.55294737]]\n",
      "Normalized Cumulative Error: 0.11311397138267755\n",
      "error: 61 2.616263157894739\n",
      "Raw Cumulative Error: 6.1035894736841705\n",
      "error: [[0.        ]\n",
      " [0.26995439]\n",
      " [0.43890877]\n",
      " [0.52786316]\n",
      " [0.67181754]\n",
      " [1.68022807]\n",
      " [1.27227368]\n",
      " [0.0093193 ]\n",
      " [0.41763509]\n",
      " [0.81558947]]\n",
      "Normalized Cumulative Error: 0.2638883030457368\n",
      "error: 62 6.1035894736841705\n",
      "Raw Cumulative Error: 1.242333333333356\n",
      "error: [[0.        ]\n",
      " [0.10673333]\n",
      " [0.24746667]\n",
      " [0.0612    ]\n",
      " [0.16306667]\n",
      " [0.14833333]\n",
      " [0.1524    ]\n",
      " [0.13086667]\n",
      " [0.15886667]\n",
      " [0.0734    ]]\n",
      "Normalized Cumulative Error: 0.05371220272332766\n",
      "error: 63 1.242333333333356\n",
      "Raw Cumulative Error: 2.1419368421052596\n",
      "error: [[0.        ]\n",
      " [0.31693684]\n",
      " [0.33212632]\n",
      " [0.09118947]\n",
      " [0.10974737]\n",
      " [0.10968421]\n",
      " [0.47162105]\n",
      " [0.17255789]\n",
      " [0.43850526]\n",
      " [0.09956842]]\n",
      "Normalized Cumulative Error: 0.09260650326030578\n",
      "error: 64 2.1419368421052596\n",
      "Raw Cumulative Error: 8.330631578947429\n",
      "error: [[0.        ]\n",
      " [0.15072632]\n",
      " [1.44554737]\n",
      " [1.28282105]\n",
      " [0.97709474]\n",
      " [0.33136842]\n",
      " [1.58364211]\n",
      " [0.60208421]\n",
      " [0.17481053]\n",
      " [1.78253684]]\n",
      "Normalized Cumulative Error: 0.36017432695071483\n",
      "error: 65 8.330631578947429\n",
      "Raw Cumulative Error: 2.3877192982456172\n",
      "error: [[0.        ]\n",
      " [0.20375439]\n",
      " [0.34950877]\n",
      " [0.46826316]\n",
      " [0.32901754]\n",
      " [0.20122807]\n",
      " [0.32947368]\n",
      " [0.2527193 ]\n",
      " [0.06796491]\n",
      " [0.18578947]]\n",
      "Normalized Cumulative Error: 0.10323289213343273\n",
      "error: 66 2.3877192982456172\n",
      "Raw Cumulative Error: 15.35897894736857\n",
      "error: [[0.        ]\n",
      " [0.90245263]\n",
      " [1.94090526]\n",
      " [1.87135789]\n",
      " [1.03781053]\n",
      " [3.22626316]\n",
      " [1.47971579]\n",
      " [0.18816842]\n",
      " [1.53437895]\n",
      " [3.17792632]]\n",
      "Normalized Cumulative Error: 0.6640444788122087\n",
      "error: 67 15.35897894736857\n",
      "Raw Cumulative Error: 2.5350000000000357\n",
      "error: [[0.    ]\n",
      " [0.0354]\n",
      " [0.3608]\n",
      " [0.2358]\n",
      " [0.6826]\n",
      " [0.462 ]\n",
      " [0.0504]\n",
      " [0.0608]\n",
      " [0.0068]\n",
      " [0.6404]]\n",
      "Normalized Cumulative Error: 0.10960056391491955\n",
      "error: 68 2.5350000000000357\n",
      "Raw Cumulative Error: 1.4382105263157925\n",
      "error: [[0.        ]\n",
      " [0.0843193 ]\n",
      " [0.0226386 ]\n",
      " [0.08295789]\n",
      " [0.14872281]\n",
      " [0.28440351]\n",
      " [0.01008421]\n",
      " [0.01576491]\n",
      " [0.31144561]\n",
      " [0.47787368]]\n",
      "Normalized Cumulative Error: 0.06218094071502244\n",
      "error: 69 1.4382105263157925\n",
      "Raw Cumulative Error: 31.36933333333348\n",
      "error: [[0.        ]\n",
      " [2.10666667]\n",
      " [2.89133333]\n",
      " [5.274     ]\n",
      " [6.21066667]\n",
      " [3.98933333]\n",
      " [0.858     ]\n",
      " [0.88466667]\n",
      " [2.55066667]\n",
      " [6.604     ]]\n",
      "Normalized Cumulative Error: 1.3562511333208616\n",
      "error: 70 31.36933333333348\n",
      "Raw Cumulative Error: 1.879645614035093\n",
      "error: [[0.        ]\n",
      " [0.10876491]\n",
      " [0.13247018]\n",
      " [0.02229474]\n",
      " [0.27105965]\n",
      " [0.51482456]\n",
      " [0.21858947]\n",
      " [0.13764561]\n",
      " [0.3488807 ]\n",
      " [0.12511579]]\n",
      "Normalized Cumulative Error: 0.08126635868183374\n",
      "error: 71 1.879645614035093\n",
      "Raw Cumulative Error: 1.9112842105263326\n",
      "error: [[0.        ]\n",
      " [0.0962386 ]\n",
      " [0.18047719]\n",
      " [0.18171579]\n",
      " [0.43195439]\n",
      " [0.13619298]\n",
      " [0.26543158]\n",
      " [0.22232982]\n",
      " [0.12509123]\n",
      " [0.27185263]]\n",
      "Normalized Cumulative Error: 0.0826342513906765\n",
      "error: 72 1.9112842105263326\n",
      "Raw Cumulative Error: 22.24507368421065\n",
      "error: [[0.        ]\n",
      " [2.29997544]\n",
      " [2.89295088]\n",
      " [1.41392632]\n",
      " [4.35390175]\n",
      " [3.28787719]\n",
      " [1.51585263]\n",
      " [0.53517193]\n",
      " [1.97719649]\n",
      " [3.96822105]]\n",
      "Normalized Cumulative Error: 0.9617643471867416\n",
      "error: 73 22.24507368421065\n",
      "Raw Cumulative Error: 8.353701754386044\n",
      "error: [[0.        ]\n",
      " [0.89498246]\n",
      " [1.87503509]\n",
      " [1.29405263]\n",
      " [1.29407018]\n",
      " [0.76308772]\n",
      " [0.50089474]\n",
      " [1.32387719]\n",
      " [0.21285965]\n",
      " [0.19484211]]\n",
      "Normalized Cumulative Error: 0.36117176451982264\n",
      "error: 74 8.353701754386044\n",
      "Raw Cumulative Error: 26.956378947368535\n",
      "error: [[0.        ]\n",
      " [1.95420702]\n",
      " [2.75141404]\n",
      " [5.74562105]\n",
      " [4.32582807]\n",
      " [3.30003509]\n",
      " [1.13824211]\n",
      " [0.96355088]\n",
      " [2.41534386]\n",
      " [4.36213684]]\n",
      "Normalized Cumulative Error: 1.1654573308622547\n",
      "error: 75 26.956378947368535\n",
      "Raw Cumulative Error: 2.646010526315786\n",
      "error: [[0.        ]\n",
      " [0.08744561]\n",
      " [0.64489123]\n",
      " [0.25633684]\n",
      " [0.18621754]\n",
      " [0.23877193]\n",
      " [0.04867368]\n",
      " [0.4661193 ]\n",
      " [0.15856491]\n",
      " [0.55898947]]\n",
      "Normalized Cumulative Error: 0.11440009696608251\n",
      "error: 76 2.646010526315786\n",
      "Raw Cumulative Error: 4.270526315789484\n",
      "error: [[0.        ]\n",
      " [0.4412807 ]\n",
      " [0.1684386 ]\n",
      " [0.07784211]\n",
      " [0.27712281]\n",
      " [0.63240351]\n",
      " [0.47568421]\n",
      " [1.25203509]\n",
      " [0.57724561]\n",
      " [0.36847368]]\n",
      "Normalized Cumulative Error: 0.18463593389507876\n",
      "error: 77 4.270526315789484\n",
      "Raw Cumulative Error: 28.701421052631726\n",
      "error: [[0.        ]\n",
      " [2.55885965]\n",
      " [3.2617193 ]\n",
      " [5.76857895]\n",
      " [4.8194386 ]\n",
      " [2.53629825]\n",
      " [1.71915789]\n",
      " [0.45498246]\n",
      " [2.76412281]\n",
      " [4.81826316]]\n",
      "Normalized Cumulative Error: 1.240904115395636\n",
      "error: 78 28.701421052631726\n"
     ]
    }
   ],
   "source": [
    "prototypes = X_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "Errors = []\n",
    "Norm_Errors= []\n",
    "No_path_index = []\n",
    "for i in range(len(X_test)):\n",
    "    error, norm_error = baseline_one_step(prototypes,f,X_test.iloc[i].values,preds.mean())\n",
    "    print(\"error:\",i, error)\n",
    "    if error is not None:\n",
    "        Errors.append(error)\n",
    "        Norm_Errors.append(norm_error)\n",
    "    else:\n",
    "        No_path_index.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3972588856873689"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Norm_Errors).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 106.19400000000026\n",
      "Normalized Cumulative Error: 4.591290841964826\n",
      "error: 0 106.19400000000026\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 0.3360000000000056\n",
      "Normalized Cumulative Error: 0.014526938649078135\n",
      "error: 1 0.3360000000000056\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 52.74600000000041\n",
      "Normalized Cumulative Error: 2.280469958286513\n",
      "error: 2 52.74600000000041\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 82.06800000000025\n",
      "Normalized Cumulative Error: 3.5482047650372857\n",
      "error: 3 82.06800000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 18.798000000000037\n",
      "Normalized Cumulative Error: 0.8127303354921629\n",
      "error: 4 18.798000000000037\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 94.18200000000027\n",
      "Normalized Cumulative Error: 4.071952785260291\n",
      "error: 5 94.18200000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 11.244000000000003\n",
      "Normalized Cumulative Error: 0.4861336255066424\n",
      "error: 6 11.244000000000003\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 108.17400000000023\n",
      "Normalized Cumulative Error: 4.67689601614689\n",
      "error: 7 108.17400000000023\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 23.268\n",
      "Normalized Cumulative Error: 1.0059905014486439\n",
      "error: 8 23.268\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 72.03600000000026\n",
      "Normalized Cumulative Error: 3.1144718825148177\n",
      "error: 9 72.03600000000026\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 24.41400000000001\n",
      "Normalized Cumulative Error: 1.0555377386267493\n",
      "error: 10 24.41400000000001\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 20.082000000000008\n",
      "Normalized Cumulative Error: 0.8682439939011378\n",
      "error: 11 20.082000000000008\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 39.696\n",
      "Normalized Cumulative Error: 1.7162540375410593\n",
      "error: 12 39.696\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 99.01800000000024\n",
      "Normalized Cumulative Error: 4.281036937959518\n",
      "error: 13 99.01800000000024\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 18.882000000000012\n",
      "Normalized Cumulative Error: 0.8163620701544313\n",
      "error: 14 18.882000000000012\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 39.66000000000008\n",
      "Normalized Cumulative Error: 1.7146975798286617\n",
      "error: 15 39.66000000000008\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 20.394000000000005\n",
      "Normalized Cumulative Error: 0.8817332940752816\n",
      "error: 16 20.394000000000005\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 66.73800000000024\n",
      "Normalized Cumulative Error: 2.8854131891731067\n",
      "error: 17 66.73800000000024\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 38.86800000000014\n",
      "Normalized Cumulative Error: 1.6804555101558376\n",
      "error: 18 38.86800000000014\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 41.898000000000025\n",
      "Normalized Cumulative Error: 1.8114573676162673\n",
      "error: 19 41.898000000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 13.494000000000014\n",
      "Normalized Cumulative Error: 0.583412232531718\n",
      "error: 20 13.494000000000014\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 14.994000000000142\n",
      "Normalized Cumulative Error: 0.648264637215107\n",
      "error: 21 14.994000000000142\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 61.50600000000024\n",
      "Normalized Cumulative Error: 2.6592080016374653\n",
      "error: 22 61.50600000000024\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 43.59\n",
      "Normalized Cumulative Error: 1.884610880099123\n",
      "error: 23 43.59\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 79.23000000000026\n",
      "Normalized Cumulative Error: 3.4255040153763248\n",
      "error: 24 79.23000000000026\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 117.84000000000026\n",
      "Normalized Cumulative Error: 5.094804911926614\n",
      "error: 25 117.84000000000026\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 19.902\n",
      "Normalized Cumulative Error: 0.8604617053391316\n",
      "error: 26 19.902\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 28.800000000000004\n",
      "Normalized Cumulative Error: 1.2451661699209622\n",
      "error: 27 28.800000000000004\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 97.77600000000027\n",
      "Normalized Cumulative Error: 4.227339146881678\n",
      "error: 28 97.77600000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 5.13600000000001\n",
      "Normalized Cumulative Error: 0.22205463363590533\n",
      "error: 29 5.13600000000001\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 27.966000000000008\n",
      "Normalized Cumulative Error: 1.2091082329170013\n",
      "error: 30 27.966000000000008\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 23.003999999999976\n",
      "Normalized Cumulative Error: 0.9945764782243675\n",
      "error: 31 23.003999999999976\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 15.978000000000044\n",
      "Normalized Cumulative Error: 0.6908078146874024\n",
      "error: 32 15.978000000000044\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 39.504000000000104\n",
      "Normalized Cumulative Error: 1.7079529297415907\n",
      "error: 33 39.504000000000104\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 16.224000000000004\n",
      "Normalized Cumulative Error: 0.7014436090554754\n",
      "error: 34 16.224000000000004\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 55.110000000000184\n",
      "Normalized Cumulative Error: 2.3826773480675154\n",
      "error: 35 55.110000000000184\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 17.634\n",
      "Normalized Cumulative Error: 0.7624048694578558\n",
      "error: 36 17.634\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 95.24400000000028\n",
      "Normalized Cumulative Error: 4.117868287776127\n",
      "error: 37 95.24400000000028\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 20.33400000000001\n",
      "Normalized Cumulative Error: 0.8791391978879464\n",
      "error: 38 20.33400000000001\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 5.7840000000000025\n",
      "Normalized Cumulative Error: 0.2500708724591267\n",
      "error: 39 5.7840000000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 24.503999999999998\n",
      "Normalized Cumulative Error: 1.0594288829077518\n",
      "error: 40 24.503999999999998\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 85.78200000000024\n",
      "Normalized Cumulative Error: 3.7087793190333427\n",
      "error: 41 85.78200000000024\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 61.54800000000027\n",
      "Normalized Cumulative Error: 2.661023868968601\n",
      "error: 42 61.54800000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 108.79200000000027\n",
      "Normalized Cumulative Error: 4.703615206876446\n",
      "error: 43 108.79200000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 22.704\n",
      "Normalized Cumulative Error: 0.9816059972876918\n",
      "error: 44 22.704\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 6.804000000000002\n",
      "Normalized Cumulative Error: 0.2941705076438274\n",
      "error: 45 6.804000000000002\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 31.362000000000002\n",
      "Normalized Cumulative Error: 1.355934077120181\n",
      "error: 46 31.362000000000002\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 52.554000000000215\n",
      "Normalized Cumulative Error: 2.2721688504870317\n",
      "error: 47 52.554000000000215\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 137.24400000000028\n",
      "Normalized Cumulative Error: 5.933735618910863\n",
      "error: 48 137.24400000000028\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 79.00200000000027\n",
      "Normalized Cumulative Error: 3.4156464498644508\n",
      "error: 49 79.00200000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 22.104000000000006\n",
      "Normalized Cumulative Error: 0.9556650354143387\n",
      "error: 50 22.104000000000006\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 123.28800000000025\n",
      "Normalized Cumulative Error: 5.330348845736663\n",
      "error: 51 123.28800000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 120.13200000000028\n",
      "Normalized Cumulative Error: 5.193899386282825\n",
      "error: 52 120.13200000000028\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 50.81400000000035\n",
      "Normalized Cumulative Error: 2.1969400610543124\n",
      "error: 53 50.81400000000035\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 20.184000000000047\n",
      "Normalized Cumulative Error: 0.8726539574196096\n",
      "error: 54 20.184000000000047\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 42.45000000000002\n",
      "Normalized Cumulative Error: 1.8353230525397521\n",
      "error: 55 42.45000000000002\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 28.074000000000012\n",
      "Normalized Cumulative Error: 1.213777606054205\n",
      "error: 56 28.074000000000012\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 25.235999999999997\n",
      "Normalized Cumulative Error: 1.091076856393243\n",
      "error: 57 25.235999999999997\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 116.51400000000025\n",
      "Normalized Cumulative Error: 5.037475386186503\n",
      "error: 58 116.51400000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 121.65600000000025\n",
      "Normalized Cumulative Error: 5.259789429441142\n",
      "error: 59 121.65600000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 8.634\n",
      "Normalized Cumulative Error: 0.3732904413575551\n",
      "error: 60 8.634\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 22.48200000000002\n",
      "Normalized Cumulative Error: 0.9720078413945519\n",
      "error: 61 22.48200000000002\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 10.764000000000088\n",
      "Normalized Cumulative Error: 0.4653808560079634\n",
      "error: 62 10.764000000000088\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 11.994000000000035\n",
      "Normalized Cumulative Error: 0.5185598278483355\n",
      "error: 63 11.994000000000035\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 20.41200000000007\n",
      "Normalized Cumulative Error: 0.8825115229314849\n",
      "error: 64 20.41200000000007\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 106.95600000000027\n",
      "Normalized Cumulative Error: 4.624235863543984\n",
      "error: 65 106.95600000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 7.458000000000077\n",
      "Normalized Cumulative Error: 0.3224461560857858\n",
      "error: 66 7.458000000000077\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 81.07800000000027\n",
      "Normalized Cumulative Error: 3.5054021779462534\n",
      "error: 67 81.07800000000027\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 22.05600000000001\n",
      "Normalized Cumulative Error: 0.9535897584644706\n",
      "error: 68 22.05600000000001\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 18.834000000000007\n",
      "Normalized Cumulative Error: 0.8142867932045628\n",
      "error: 69 18.834000000000007\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 130.22400000000025\n",
      "Normalized Cumulative Error: 5.630226364992628\n",
      "error: 70 130.22400000000025\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 20.124000000000002\n",
      "Normalized Cumulative Error: 0.8700598612322723\n",
      "error: 71 20.124000000000002\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 7.260000000000005\n",
      "Normalized Cumulative Error: 0.3138856386675761\n",
      "error: 72 7.260000000000005\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 86.13600000000024\n",
      "Normalized Cumulative Error: 3.724084486538621\n",
      "error: 73 86.13600000000024\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 8.513999999999982\n",
      "Normalized Cumulative Error: 0.36810224898288363\n",
      "error: 74 8.513999999999982\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 104.06400000000028\n",
      "Normalized Cumulative Error: 4.499200427314421\n",
      "error: 75 104.06400000000028\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 1: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 2: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 3: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 4: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Step 5: x = [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02], f(x) = 10.456\n",
      "Raw Cumulative Error: 19.464\n",
      "Normalized Cumulative Error: 0.8415248031715835\n",
      "error: 76 19.464\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 1: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 2: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 3: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 4: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Step 5: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02], f(x) = 23.451\n",
      "Raw Cumulative Error: 44.592\n",
      "Normalized Cumulative Error: 1.927932286427623\n",
      "error: 77 44.592\n",
      "Gradient Descent-Based Search (Baseline 2) Path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02], f(x) = 43.719000000000044\n",
      "Step 1: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 2: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 3: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 4: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Step 5: x = [   4.    90.    49.  2085.    21.7   80.  -498.   299. ], f(x) = 43.719000000000044\n",
      "Raw Cumulative Error: 95.51400000000025\n",
      "Normalized Cumulative Error: 4.129541720619135\n",
      "error: 78 95.51400000000025\n",
      "2.126203326791546\n"
     ]
    }
   ],
   "source": [
    "# Prediction function using your random forest model.\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Predicts the value for x using a random forest model.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Input feature vector.\n",
    "    \n",
    "    Returns:\n",
    "        float: Predicted value.\n",
    "    \"\"\"\n",
    "    x_df = pd.DataFrame([x], columns=X.columns)\n",
    "    return float(rf.predict(x_df)[0])\n",
    "\n",
    "# Finite difference gradient approximation for f(x).\n",
    "def grad_f(x, delta=1e-6):\n",
    "    \"\"\"\n",
    "    Approximates the gradient of f at x using finite differences.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Input feature vector.\n",
    "        delta (float): Small perturbation used to compute the finite difference.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Approximated gradient vector.\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "    for i in range(len(x)):\n",
    "        x_forward = np.array(x, copy=True)\n",
    "        x_backward = np.array(x, copy=True)\n",
    "        x_forward[i] += delta\n",
    "        x_backward[i] -= delta\n",
    "        grad[i] = (f(x_forward) - f(x_backward)) / (2 * delta)\n",
    "    return grad\n",
    "\n",
    "def baseline2run(prototypes, X_target, avg_abs_pred, p, max_steps=5, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Baseline 2: Gradient Descent-Based Search using a finite difference approximation.\n",
    "    \n",
    "    This function starts from the prototype that is closest to the target and performs\n",
    "    gradient descent with an update rule:\n",
    "    \n",
    "        x_{t+1} = x_t - (1/p) * grad_f(x_t)\n",
    "    \n",
    "    The process stops when the current point is within a tolerance of X_target or after a\n",
    "    maximum number of steps.\n",
    "    \n",
    "    Args:\n",
    "        prototypes (np.ndarray): Array of prototype instances.\n",
    "        X_target (np.ndarray): Target instance.\n",
    "        avg_abs_pred (float): Average absolute prediction value for normalization.\n",
    "        p (float): Parameter that scales the gradient step (step size is 1/p).\n",
    "        max_steps (int): Maximum number of gradient descent steps.\n",
    "        tol (float): Tolerance for convergence toward X_target.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (raw_cumulative_error, normalized_cumulative_error)\n",
    "    \"\"\"\n",
    "    # Find the prototype closest to the target.\n",
    "    distances = np.linalg.norm(prototypes - X_target, axis=1)\n",
    "    closest_proto_index = np.argmin(distances)\n",
    "    X_proto = prototypes[closest_proto_index]\n",
    "    \n",
    "    f_target = f(X_target)\n",
    "    path = [X_proto.copy()]\n",
    "    f_values = [f(X_proto)]\n",
    "    x_current = X_proto.copy()\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Approximate the gradient at the current point.\n",
    "        grad = grad_f(x_current)\n",
    "        # Update the current point.\n",
    "        x_new = x_current - (1 / p) * grad\n",
    "        path.append(x_new.copy())\n",
    "        f_values.append(f(x_new))\n",
    "        \n",
    "        # Check if the new point is close enough to the target.\n",
    "        if np.linalg.norm(x_new - X_target) < tol:\n",
    "            break\n",
    "        \n",
    "        x_current = x_new\n",
    "    \n",
    "    raw_cumulative_error = sum(abs(val - f_target) for val in f_values)\n",
    "    normalized_cumulative_error = raw_cumulative_error / avg_abs_pred\n",
    "    \n",
    "    print(\"Gradient Descent-Based Search (Baseline 2) Path:\")\n",
    "    for i, (x_val, fx_val) in enumerate(zip(path, f_values)):\n",
    "        print(f\"Step {i}: x = {x_val}, f(x) = {fx_val}\")\n",
    "    print(\"Raw Cumulative Error:\", raw_cumulative_error)\n",
    "    print(\"Normalized Cumulative Error:\", normalized_cumulative_error)\n",
    "    \n",
    "    return raw_cumulative_error, normalized_cumulative_error\n",
    "\n",
    "prototypes = X_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "Errors = []\n",
    "Norm_Errors= []\n",
    "No_path_index = []\n",
    "for i in range(len(X_test)):\n",
    "    error, norm_error = baseline2run(prototypes,X_test.iloc[i].values,preds.mean(),2)\n",
    "    print(\"error:\",i, error)\n",
    "    if error is not None:\n",
    "        Errors.append(error)\n",
    "        Norm_Errors.append(norm_error)\n",
    "    else:\n",
    "        No_path_index.append(i) \n",
    "        \n",
    "print(np.array(Norm_Errors).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8537843704062908"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(norm_error).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = run_search_path(prototypes,X_test.iloc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_proto [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02] org_proto [10.456]\n",
      "X_proto [8.000e+00 3.500e+02 3.600e+01 4.732e+03 1.850e+01 7.300e+01 1.000e+00\n",
      " 2.400e+01] pred_prototype adj [12.126]\n",
      "X_target [8.0e+00 3.5e+02 3.6e+01 4.1e+03 1.3e+01 7.3e+01 1.0e+00 2.4e+01] pred_target [13.81]\n",
      "Found a path:\n",
      "Step 0: x = [8.000e+00 3.500e+02 3.600e+01 4.732e+03 1.850e+01 7.300e+01 1.000e+00\n",
      " 2.400e+01], f(x) = [12.126]\n",
      "Step 1: x = [8.000e+00 3.500e+02 3.600e+01 4.732e+03 1.300e+01 7.300e+01 1.000e+00\n",
      " 2.400e+01], f(x) = 12.57\n",
      "Step 2: x = [8.0e+00 3.5e+02 3.6e+01 4.1e+03 1.3e+01 7.3e+01 1.0e+00 2.4e+01], f(x) = 13.81\n",
      "Cumulative error: 0.036338618518518696\n",
      "error: 71 0.036338618518518696\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [   4.   146.    91.  2815.    14.5   77.     3.    88. ] pred_prototype adj [23.367]\n",
      "X_target [   6.   146.    91.  2815.    14.5   77.     3.    88. ] pred_target [22.241]\n",
      "Found a path:\n",
      "Step 0: x = [   4.   146.    91.  2815.    14.5   77.     3.    88. ], f(x) = [23.367]\n",
      "Step 1: x = [   6.   146.    91.  2815.    14.5   77.     3.    88. ], f(x) = 22.241\n",
      "Cumulative error: 0.028292562962962696\n",
      "error: 72 0.028292562962962696\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   3.    70.    49.  2124.    21.7   80.     3.   299. ] pred_prototype adj [42.793]\n",
      "X_target [   3.    70.    84.  2124.    13.5   73.     3.   172. ] pred_target [29.363]\n",
      "Found a path:\n",
      "Step 0: x = [   3.    70.    49.  2124.    21.7   80.     3.   299. ], f(x) = [42.793]\n",
      "Step 1: x = [   3.    70.    49.  2124.    21.7   80.     3.   172. ], f(x) = 41.792000000000016\n",
      "Step 2: x = [   3.    70.    84.  2124.    21.7   80.     3.   172. ], f(x) = 40.341000000000015\n",
      "Step 3: x = [   3.    70.    84.  2124.    17.6   80.     3.   172. ], f(x) = 38.788\n",
      "Step 4: x = [   3.    70.    84.  2124.    17.6   73.     3.   172. ], f(x) = 29.423000000000002\n",
      "Step 5: x = [   3.    70.    84.  2124.    13.5   73.     3.   172. ], f(x) = 29.363000000000003\n",
      "Cumulative error: 4.61368520740742\n",
      "error: 73 4.61368520740742\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01] pred_prototype adj [23.429]\n",
      "X_target [6.000e+00 2.250e+02 7.900e+01 3.465e+03 1.660e+01 8.100e+01 1.000e+00\n",
      " 7.100e+01] pred_target [22.032]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01], f(x) = [23.429]\n",
      "Step 1: x = [4.000e+00 1.880e+02 7.900e+01 2.855e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01], f(x) = 23.007999999999996\n",
      "Step 2: x = [5.000e+00 1.880e+02 7.900e+01 2.855e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01], f(x) = 22.798\n",
      "Step 3: x = [5.00e+00 1.88e+02 7.90e+01 3.16e+03 1.66e+01 7.80e+01 1.00e+00 7.10e+01], f(x) = 21.480999999999995\n",
      "Step 4: x = [5.000e+00 1.880e+02 7.900e+01 3.465e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01], f(x) = 21.384999999999994\n",
      "Step 5: x = [6.000e+00 1.880e+02 7.900e+01 3.465e+03 1.660e+01 7.800e+01 1.000e+00\n",
      " 7.100e+01], f(x) = 20.671999999999997\n",
      "Cumulative error: 0.10208458148148236\n",
      "error: 74 0.10208458148148236\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02] pred_prototype adj [43.719]\n",
      "X_target [4.000e+00 9.800e+01 7.400e+01 2.164e+03 1.500e+01 7.200e+01 1.000e+00\n",
      " 1.030e+02] pred_target [26.375]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = [43.719]\n",
      "Step 1: x = [4.0000e+00 9.0000e+01 4.9000e+01 2.1245e+03 2.1700e+01 8.0000e+01\n",
      " 1.0000e+00 2.9900e+02], f(x) = 43.644000000000034\n",
      "Step 2: x = [4.0000e+00 9.4000e+01 4.9000e+01 2.1245e+03 2.1700e+01 8.0000e+01\n",
      " 1.0000e+00 2.9900e+02], f(x) = 42.92600000000004\n",
      "Step 3: x = [4.000e+00 9.400e+01 4.900e+01 2.164e+03 2.170e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = 42.25800000000003\n",
      "Step 4: x = [4.000e+00 9.400e+01 6.150e+01 2.164e+03 2.170e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = 40.75200000000004\n",
      "Step 5: x = [4.000e+00 9.400e+01 6.150e+01 2.164e+03 1.835e+01 8.000e+01 1.000e+00\n",
      " 2.990e+02], f(x) = 39.128000000000014\n",
      "Cumulative error: 0.17147371111111373\n",
      "error: 75 0.17147371111111373\n",
      "X_proto [8.000e+00 3.040e+02 3.900e+01 4.732e+03 1.850e+01 7.000e+01 1.000e+00\n",
      " 1.610e+02] org_proto [10.456]\n",
      "X_proto [8.000e+00 3.500e+02 2.400e+01 4.732e+03 1.850e+01 7.300e+01 1.000e+00\n",
      " 5.800e+01] pred_prototype adj [12.146]\n",
      "X_target [8.000e+00 3.500e+02 2.400e+01 4.082e+03 1.300e+01 7.300e+01 1.000e+00\n",
      " 5.800e+01] pred_target [13.7]\n",
      "Found a path:\n",
      "Step 0: x = [8.000e+00 3.500e+02 2.400e+01 4.732e+03 1.850e+01 7.300e+01 1.000e+00\n",
      " 5.800e+01], f(x) = [12.146]\n",
      "Step 1: x = [8.000e+00 3.500e+02 2.400e+01 4.082e+03 1.850e+01 7.300e+01 1.000e+00\n",
      " 5.800e+01], f(x) = 13.421\n",
      "Step 2: x = [8.000e+00 3.500e+02 2.400e+01 4.082e+03 1.300e+01 7.300e+01 1.000e+00\n",
      " 5.800e+01], f(x) = 13.7\n",
      "Cumulative error: 0.056426766666666586\n",
      "error: 76 0.056426766666666586\n",
      "X_proto [4.000e+00 1.510e+02 7.900e+01 2.855e+03 1.760e+01 7.800e+01 1.000e+00\n",
      " 2.040e+02] org_proto [23.451]\n",
      "X_proto [4.000e+00 1.510e+02 2.700e+01 2.855e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 1.300e+01] pred_prototype adj [23.367]\n",
      "X_target [8.000e+00 3.040e+02 2.700e+01 3.433e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 1.300e+01] pred_target [16.019]\n",
      "Found a path:\n",
      "Step 0: x = [4.000e+00 1.510e+02 2.700e+01 2.855e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 1.300e+01], f(x) = [23.367]\n",
      "Step 1: x = [4.000e+00 1.510e+02 2.700e+01 3.144e+03 1.200e+01 7.800e+01 1.000e+00\n",
      " 1.300e+01], f(x) = 21.709\n",
      "Step 2: x = [4.000e+00 1.510e+02 2.700e+01 3.144e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 1.300e+01], f(x) = 20.953999999999997\n",
      "Step 3: x = [4.000e+00 1.510e+02 2.700e+01 3.433e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 1.300e+01], f(x) = 20.872\n",
      "Step 4: x = [4.000e+00 3.040e+02 2.700e+01 3.433e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 1.300e+01], f(x) = 18.556\n",
      "Step 5: x = [8.000e+00 3.040e+02 2.700e+01 3.433e+03 1.200e+01 7.000e+01 1.000e+00\n",
      " 1.300e+01], f(x) = 16.019000000000002\n",
      "Cumulative error: 1.0448403851851864\n",
      "error: 77 1.0448403851851864\n",
      "X_proto [4.000e+00 9.000e+01 4.900e+01 2.085e+03 2.170e+01 8.000e+01 2.000e+00\n",
      " 2.990e+02] org_proto [43.719]\n",
      "X_proto [   4.    90.    49.  2130.    21.7   80.     3.   299. ] pred_prototype adj [43.507]\n",
      "X_target [   4.    97.    82.  2130.    14.5   70.     3.    94. ] pred_target [27.8]\n",
      "Found a path:\n",
      "Step 0: x = [   4.    90.    49.  2130.    21.7   80.     3.   299. ], f(x) = [43.507]\n",
      "Step 1: x = [   4.    90.    49.  2130.    21.7   80.     3.    94. ], f(x) = 41.564000000000014\n",
      "Step 2: x = [   4.    90.    49.  2130.    14.5   80.     3.    94. ], f(x) = 38.98999999999998\n",
      "Step 3: x = [   4.    90.    82.  2130.    14.5   80.     3.    94. ], f(x) = 37.39999999999999\n",
      "Step 4: x = [   4.    97.    82.  2130.    14.5   80.     3.    94. ], f(x) = 35.76399999999999\n",
      "Step 5: x = [   4.    97.    82.  2130.    14.5   70.     3.    94. ], f(x) = 27.8\n",
      "Cumulative error: 5.238489233333324\n",
      "error: 78 5.238489233333324\n"
     ]
    }
   ],
   "source": [
    "prototypes = X_train.iloc[[min_index, closest_mean_index, max_index]].values\n",
    "Errors = []\n",
    "No_path_index = []\n",
    "\n",
    "Errors = [0.22916227037037423,\n",
    " 0.0,\n",
    " 0.6736127111111194,\n",
    " 3.742809488888878,\n",
    " 0.10403256296296302,\n",
    " 1.0327779777777888,\n",
    " 0.0190871703703705,\n",
    " 0.2586942259259283,\n",
    " 0.08259511111111065,\n",
    " 1.5953026481481816,\n",
    " 0.08495706296296296,\n",
    " 0.020594192592593156,\n",
    " 0.259376370370369,\n",
    " 0.1201323259259254,\n",
    " 0.12718117037037005,\n",
    " 4.439875822222238,\n",
    " 0.08621143333333404,\n",
    " 0.3852815518518502,\n",
    " 1.7985502962962987,\n",
    " 0.7609020333333324,\n",
    " 0.09234291481481556,\n",
    " 0.055900429629628476,\n",
    " 1.0167767518518653,\n",
    " 0.8909458740740779,\n",
    " 1.152274137037037,\n",
    " 0.20984899259259635,\n",
    " 0.057173862962965075,\n",
    " 0.10768147037037072,\n",
    " 4.020706674074061,\n",
    " 0.12502508148148175,\n",
    " 0.07390438518518433,\n",
    " 0.06746284444444353,\n",
    " 2.45649244814816,\n",
    " 0.076107933333333,\n",
    " 0.4970397296296483,\n",
    " 0.1111818518518521,\n",
    " 3.808565518518555,\n",
    " 0.13458851851851916,\n",
    " 0.0,\n",
    " 0.12608407407407418,\n",
    " 1.9953386000000102,\n",
    " 0.06503049629629548,\n",
    " 0.2893609629629624,\n",
    " 0.11775074074074084,\n",
    " 0.005509600000000052,\n",
    " 0.39519658148148185,\n",
    " 1.1950222333333491,\n",
    " 0.9946646666666747,\n",
    " 0.038718796296296425,\n",
    " 0.26033688148148476,\n",
    " 0.2682731925925905,\n",
    " 1.4962322851851912,\n",
    " 0.23162799629629485,\n",
    " 0.18972003333333246,\n",
    " 0.18286622962963012,\n",
    " 0.3377287518518516,\n",
    " 0.4393800888888882,\n",
    " 0.0046503407407407675,\n",
    " 0.1115544592592604,\n",
    " 0.0,\n",
    " 0.08347692962963052,\n",
    " 0.4898298111111157,\n",
    " 0.06529739629629734,\n",
    " 1.7112182518518562,\n",
    " 0.05421955925925949,\n",
    " 0.07849808518518539]\n",
    "for i in range(70, len(X_test)):\n",
    "    if i==48:\n",
    "        continue\n",
    "    if i==70:\n",
    "        continue\n",
    "    error = run_search_path(prototypes,X_test.iloc[i].values)\n",
    "    print(\"error:\",i, error)\n",
    "    if error is not None:\n",
    "        Errors.append(error)\n",
    "    else:\n",
    "        No_path_index.append(i) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22916227037037423,\n",
       " 0.0,\n",
       " 0.6736127111111194,\n",
       " 3.742809488888878,\n",
       " 0.10403256296296302,\n",
       " 1.0327779777777888,\n",
       " 0.0190871703703705,\n",
       " 0.2586942259259283,\n",
       " 0.08259511111111065,\n",
       " 1.5953026481481816,\n",
       " 0.08495706296296296,\n",
       " 0.020594192592593156,\n",
       " 0.259376370370369,\n",
       " 0.1201323259259254,\n",
       " 0.12718117037037005,\n",
       " 4.439875822222238,\n",
       " 0.08621143333333404,\n",
       " 0.3852815518518502,\n",
       " 1.7985502962962987,\n",
       " 0.7609020333333324,\n",
       " 0.09234291481481556,\n",
       " 0.055900429629628476,\n",
       " 1.0167767518518653,\n",
       " 0.8909458740740779,\n",
       " 1.152274137037037,\n",
       " 0.20984899259259635,\n",
       " 0.057173862962965075,\n",
       " 0.10768147037037072,\n",
       " 4.020706674074061,\n",
       " 0.12502508148148175,\n",
       " 0.07390438518518433,\n",
       " 0.06746284444444353,\n",
       " 2.45649244814816,\n",
       " 0.076107933333333,\n",
       " 0.4970397296296483,\n",
       " 0.1111818518518521,\n",
       " 3.808565518518555,\n",
       " 0.13458851851851916,\n",
       " 0.0,\n",
       " 0.12608407407407418,\n",
       " 1.9953386000000102,\n",
       " 0.06503049629629548,\n",
       " 0.2893609629629624,\n",
       " 0.11775074074074084,\n",
       " 0.005509600000000052,\n",
       " 0.39519658148148185,\n",
       " 1.1950222333333491,\n",
       " 0.9946646666666747,\n",
       " 0.038718796296296425,\n",
       " 0.26033688148148476,\n",
       " 0.2682731925925905,\n",
       " 1.4962322851851912,\n",
       " 0.23162799629629485,\n",
       " 0.18972003333333246,\n",
       " 0.18286622962963012,\n",
       " 0.3377287518518516,\n",
       " 0.4393800888888882,\n",
       " 0.0046503407407407675,\n",
       " 0.1115544592592604,\n",
       " 0.0,\n",
       " 0.08347692962963052,\n",
       " 0.4898298111111157,\n",
       " 0.06529739629629734,\n",
       " 1.7112182518518562,\n",
       " 0.05421955925925949,\n",
       " 0.07849808518518539]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201942426426453"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Errors).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
